# 算法设计与分析

<!-- TOC -->

- [算法设计与分析](#算法设计与分析)
- [第 1 章 绪论](#第-1-章-绪论)
  - [1.3 重要的问题类型](#13-重要的问题类型)
    - [1.3.1 排序](#131-排序)
    - [1.3.2 查找](#132-查找)
    - [1.3.3 图算法](#133-图算法)
    - [1.3.4 组合问题](#134-组合问题)
  - [1.4 基本数据结构](#14-基本数据结构)
    - [1.4.1 图](#141-图)
- [第 2 章 算法效率分析](#第-2-章-算法效率分析)
  - [2.3 非递归算法的数学分析](#23-非递归算法的数学分析)
  - [2.4 递归算法的数学分析](#24-递归算法的数学分析)
  - [2.5 计算第 n 个斐波那契数](#25-计算第-n-个斐波那契数)
- [第 3 章 蛮力法](#第-3-章-蛮力法)
  - [3.1 选择排序和冒泡排序](#31-选择排序和冒泡排序)
  - [3.2 顺序查找和蛮力字符串匹配](#32-顺序查找和蛮力字符串匹配)
  - [3.4 穷举查找](#34-穷举查找)
    - [3.4.1 旅行商问题](#341-旅行商问题)
    - [3.4.2 背包问题](#342-背包问题)
  - [3.5 深度优先查找和广度优先查找](#35-深度优先查找和广度优先查找)
- [第 4 章 减治法](#第-4-章-减治法)
  - [4.2 拓扑排序](#42-拓扑排序)
  - [4.3 生成组合对象的算法](#43-生成组合对象的算法)
    - [4.3.1 生成排列](#431-生成排列)
  - [4.4 减常因子算法](#44-减常因子算法)
    - [4.4.1 折半查找](#441-折半查找)
    - [4.4.2 假币问题](#442-假币问题)
    - [4.4.3 约瑟夫问题](#443-约瑟夫问题)
  - [4.5 减可变规模算法](#45-减可变规模算法)
    - [4.5.1 计算中值和选择问题](#451-计算中值和选择问题)
- [第 5 章 分治法](#第-5-章-分治法)
- [第 6 章 变治法](#第-6-章-变治法)
  - [6.1 预排序](#61-预排序)
- [第 7 章 时空权衡](#第-7-章-时空权衡)
  - [7.2 字符串匹配中的输入增强技术](#72-字符串匹配中的输入增强技术)
    - [7.2.1 Horspool 算法](#721-horspool-算法)
    - [7.2.2 Boyer-Moore 算法](#722-boyer-moore-算法)
- [第 8 章 动态规划](#第-8-章-动态规划)
  - [8.1 三个基本例子](#81-三个基本例子)
  - [8.2 背包问题和记忆功能](#82-背包问题和记忆功能)
    - [8.2.1 背包问题](#821-背包问题)
    - [8.2.2 记忆化](#822-记忆化)
- [第 9 章 贪婪技术](#第-9-章-贪婪技术)
- [第 11 章 算法能力的极限](#第-11-章-算法能力的极限)
  - [11.3 P, NP 和 NP 完全问题](#113-p-np-和-np-完全问题)
    - [11.3.1 P 和 NP 问题](#1131-p-和-np-问题)
- [第 12 章 超越算法能力的极限](#第-12-章-超越算法能力的极限)
  - [12.1 回溯法](#121-回溯法)
    - [12.1.1 n 皇后问题](#1211-n-皇后问题)
    - [12.1.3 子集和问题](#1213-子集和问题)
    - [12.1.4 一般性说明](#1214-一般性说明)
  - [12.2 分支界限法](#122-分支界限法)
    - [12.2.1 分配问题](#1221-分配问题)

<!-- /TOC -->

# 第 1 章 绪论

## 1.3 重要的问题类型

+ 排序
+ 查找
+ 字符串处理
+ 图问题
+ 组合问题
+ 几何问题
+ 数值问题    

### 1.3.1 排序

排序使我们更容易求解和列表相关的问题。其中最重要的是查找问题：这就是为什么字典、电话簿和班级名册
都是拍好序的。同样原因，在很多其他领域的重要算法（例如几何算法和数据压缩）中，排序也被作为一个
辅助步骤。贪婪算法也要求有序的输入。    

### 1.3.2 查找

有很多查找算法可供选择，其中既包括直截了当的顺序搜索，也包括效率极高但应用受限的这班查找，还有
那些将原集合用另一种形式表示以方便查找的算法。   

### 1.3.3 图算法

基本的图算法包括图的遍历算法（如何能一次访问到网络中的所有节点）、最短路线算法（两个城市之间
的最佳路线是哪条？）以及有向图的拓扑排序（一系列课程的预备课程是相互一致的，还是自相矛盾的？）。    

有一些图问题在计算上是非常困难的。其中最广为人知的恐怕要数旅行商问题和图填色问题了。**旅行商问题**
(traveling salesman problem, TSP) 就是要找出访问 n 个城市的最短路径，并且保证每个城市
只访问一次。**图填色问题** 就是要用最少种类的颜色为图中的顶点着色，并保证任何两个邻接顶点
的颜色都不同。这个问题源于若干应用，例如安排事务进度：如果用以边相连的顶点代表事务，当且
仅当独立事务无法排定同时发生时，图填色问题的解才能生成一张最优的日程表。   

### 1.3.4 组合问题

从更抽象的角度来看，旅行商问题和图着色问题都是 **组合问题** 的特例。有一些问题要求寻找一个
组合对象，例如一个排列、一个组合或者一个子集，这些对象能够满足特定的条件并具有我们想要的
特性，如价值最大化或成本最小化。    

一般说来，无论从理论角度还是实践角度来看，组合问题都是计算领域中最难的问题。这时出于以下原因。
第一，通常，随着问题规模的增大，组合对象的数量增长极快，即使是中等规模的实例，其组合的规模也
会达到不可思议的数量级。第二，还没有一种已知算法能在可接受的时间内，精确地解决绝大多数这类
问题。而且，大多数计算机科学家认为这样的算法是不存在的。但这个猜想即没被证实，也没被证伪。    

有些组合问题用高效的算法求解，但我们应该把它们当作幸运的例外。这些例外中就包含前面提到的
最短路径算法。    

## 1.4 基本数据结构

### 1.4.1 图

几个概念：   

+ 有向和无向
+ 有权和无权
+ 完全图
+ 邻接表
+ 邻接矩阵
+ 路径
+ 简单路径
+ 连通性和连通分量
+ 邻接
+ 自环
+ 平行边    

**状态空间树**(state-space tree)，它强调了两种重要的算法设计技术：**回溯** 和 **分支界限**。   

顶点 v 的深度是从根到 v 的简单路径的长度。树的高度是从根到叶节点的最长简单路径的长度。    

# 第 2 章 算法效率分析

## 2.3 非递归算法的数学分析

分析非递归算法效率的通用方案：   

1. 决定用哪个（哪些）参数表示输入规模
2. 找出算法的基本操作（作为一个规律，它总是位于算法的最内层循环中）
3. 检查基本操作的执行次数是否只依赖于输入规模。如果它还依赖与一些其他的特性，则最差效率、平均
效率以及最优效率需要分别研究
4. 建立一个算法基本操作执行次数的求和表达式
5. 利用求和运算的标准公式和法则来建立一个操作次数的闭合公式，或者至少确定它的增长次数   


## 2.4 递归算法的数学分析

分析递归算法时间效率的通用方案：   

1. 决定用哪个（哪些）参数作为输入规模的度量标准
2. 找出算法的基本操作
3. 检查一下，对于相同规模的不同输入，基本操作的执行次数是否可能不同。如果有这种可能，则必须
对最差效率、平均效率以及最优效率做单独研究
4. 对于算法基本操作的执行次数，建立一个递归关系以及相应的初始条件
5. 解这个递归式，或者至少确定它的解的增长次数    

## 2.5 计算第 n 个斐波那契数

斐波那契数列可以用一个简单的递推式和两个初始条件来定义：   

当 n &gt; 1 时，F(n) = F(n-1) + F(n-2)    
    F(0) = 0，  F(1) = 1    

首先，先给出一个求解第 n 个斐波那契数的明确的公式。如果试着应用反向替换法来接递归公式。我们将
无法得到一个容易识别的模式。但我们可以改用另外一个定理。这个定理描述了如何求解
**带常系数的齐次二阶线性递推式**。    

ax(n) + bx(n-1) + cx(n-2) = 0    

其实,a, b, c 都是固定的实数，称为该递推式的系数，x(n) 是一个待解的未知数列的一般项。将该定理
应用到一个具有给定初始条件的递推关系中，我们将获得下列公式：    

# 第 3 章 蛮力法

**蛮力法**(brute force) 是一种简单直接地解决问题的方法，常常直接基于问题的描述和所涉及的
概念定义。    

虽然巧妙和高效的算法很少来自于蛮力法，但我们不应该忽略它作为一种重要的算法设计策略的地位。第一，
和其他某些策略不同，我们可以应用蛮力法解决广阔领域的各种问题。实际上，它可能是唯一一种几乎
什么问题都能解决的一般性方法。第二，对于一些重要的问题来说，蛮力法可以产生一些合理的算法，
它们多少具备一些实用价值，而且不必限制实例的规模。第三，如果要解决的问题实例不多，而且蛮力法
可以用一种能够接受的速度对实例求解，那么，设计一个更高效算法所花费的代价很可能是不值得的。    

## 3.1 选择排序和冒泡排序

选择排序略了。   

冒泡排序比较表中的相邻元素，如果它们是逆序的话就交换它们的位置。重复多次以后，最终，最大的元素
就“沉到”列表的最后一个位置。第二遍操作将第二大的元素沉下去。这样一直做，直到 n - 1 遍以后，
该列表就排好序了。    

```go
func BubbleSort(arr []int) {
	length := len(arr)

	for i := 0; i < length-1; i++ {
		for j := 0; j < length-1-i; j++ {
			if arr[j] > arr[j+1] {
				swap(arr, j, j+1)
			}
		}
	}
}
```   

这里仔细分析一下两层循环的临界条件，外层循环每迭代一次，都有一个数下沉到最后，那么理论上一共
需要迭代 n 次，但是介于只剩一个数的时候其实就已经不用迭代了，因此实际上只用迭代 n-1 次，因此
i 的最大可取值为 n-2。内层循环，每次迭代的范围是从 0 到当前未排序的数组的倒数第二个元素，即
n-2-i。    

## 3.2 顺序查找和蛮力字符串匹配

顺序查找略。   

蛮力字符串匹配：   

```js
function BruteForceStringMatch(text, pattern) {
  const tLen = text.length;
  const pLen = pattern.length;

  // 注意这里临界值
  for (let i = 0; i <= tLen-pLen; i++) {
    for (let j = 0; j < pLen; j++) {
      if (text[i+j] !== pattern[j]) {
        break;
      }
    }
    if (j === pLen) {
      return i;
    }
  }
  return -1
}
```   

在移动模式之前，算法可能要做足 m 次比较（m 是 pattern 的长度），而 n-m+1 次尝试的每一次
都可能会遇到这种情况。因此在最坏的情况下，该算法属于 O(mn)。然而，对于在自然语言文本中
查找词的典型问题，我们可以认为大多数移动都发生在很少的几次比较之后。所以，该算法的平均效率
应该比最差效率好的多。事实上也是这样，在查找随机文本时，它能够显示出线性的效率，即 O(n)。    

## 3.4 穷举查找

许多重要的问题要求在一个复杂度随实例规模指数增长的域中，查找一个具有特定属性的元素。无论是
明智还是暗指，一般来说，这种问题往往涉及组合对象，例如排列、组合以及一个给定集合的子集。许多
这样的问题都是最优问题：它们要求找到一个元素，能使某些期望的特性最大化或最小化，例如路径的
长度或分配的成本。    

对于组合问题来说，**穷举查找** 是一种简单的蛮力方法。它要求生成问题域中的每一个元素，选出
其中满足问题约束的元素，然后再找出一个期望元素。    

### 3.4.1 旅行商问题

这个问题要求找出一条 n 个给定的城市间的最短路径，使我们在回到出发的城市之前，对每个城市都
只访问一次。这个问题可以很方便地用加权图来建模，也就是说，用图的顶点代表城市，用边的权重
表示城市间的距离。这样该问题就可以表述为求一个图的最短 **哈密顿回路** 问题。我们把哈密顿
回路定义为一个对图的每个顶点都只穿越一次的回路。    

很容易看出，哈密顿回路可以定义为 n+1 个相邻顶点的一个序列，其中，第一个和最后一个顶点是
相同的，而其他 n-1 个顶点都是互不相同的。因此，可以通过生成 n-1 个中间城市的组合来得到
所有的旅行线路，计算这些线路的长度，然后求得最短的线路。   

### 3.4.2 背包问题

给定 n 个重量为 w1, w2, ..., wn，价值为 v1, v2, ..., vn 的物品和一个承重为 W 的背包，
求这些物品中一个最有价值的子集，并且要能够装到背包中。    

在这个问题中，穷举查找需要考虑给定的 n 个物品集合的所有子集，为了找出可行的子集，要计算出每个
子集的总重量，然后在它们中间找到价值最大的子集。因为一个 n 元素集合的子集数量是 2^n，所以
不论生成独立子集的效率有多高，穷举查找都会导致一个 Ω(2^n) 的算法。    

因此，不论对旅行商问题还是背包问题，穷举查找型算法对于任何输入都是非常低效率的。实际上，这两个
问题就是所谓的 **NP困难问题** 中最著名的例子。对于 NP 困难问题，目前没有已知的效率可以
用多项式来表示的算法。而且，大多数计算机科学家相信，这样的算法是不存在的。一些更复杂的方法
—— 回溯法和分支界限法使我们可以在优于指数级的效率下解决该问题的部分实例。    

## 3.5 深度优先查找和广度优先查找

在深度优先查找遍历的时候构造一个所谓的深度优先查找森林也是非常有用的。遍历的初始节点可以作为
这样一个森林第一棵树的根。无论何时，如果第一次遇到一个新的未访问顶点，它是从哪个顶点
被访问到的，就把它附加为那个顶点的子女。连接这样两个顶点的边称为 **树向边**，因为所有这种
边的集合构成了一个森林。该算法也可能会遇到一条指向已访问顶点的边，并且这个顶点不是他的直接
前驱（即它在树中的父母），我们把这种边称为 **回边**，因为这条边在一个深度优先查找森林中，
把一个顶点和它的非父母祖先连在了一起。   

# 第 4 章 减治法

**减治法** 技术利用了一个问题给定实例的解和同样问题较小实例的解之间的某种关系。一旦建立了
这种关系，我们即可以从顶至下，也可以从底至上地运用该关系。虽然自顶向下会自然导致出递归算法，
但从本章的例子可以看出，最终还是非递归实现较好。自底向上版本往往是迭代实现的，从求解问题的一个
较小实例开始，该方法有时也称为 **增量法**。   

减治法有 3 种主要的变化形式：   

+ 减去一个常量
+ 减去一个常量因子
+ 减去的规模是可变的    

在 **减常量** 变化形式中，每次算法迭代总是从实例中减去一个相同的常量。一般来说，这个常量
等于 1。    

作为一个例子，考虑指数问题 a<sup>n</sup> 的值，其中 a != 0, n 为非负整数，很明显，规模
为 n 的实例和规模为 n-1 的实例的关系，可由公式 a<sup>n</sup> = a<sup>n-1</sup> * a
来描述。所以函数 f(n) = a<sup>n</sup> 即可以用它的递归定义：    

```
f(n) = f(n-1) * a    // n > 0
     = a             // n = 0
```    

从顶至下地计算，也可以从底至上地把 a 自乘 n-1 次。     

**减常因子** 技术意味着在算法的每次迭代中，总是从实例的规模中减去一个相同的常数因子。在大多数
应用中，这样的常数因子等于2.    

继续看指数问题，规模减半的实例计算就是 a<sup>n/2</sup> 的值，它们之间有着明显的关系：
a<sup>n</sup> = (a<sup>n/2</sup>)<sup>2</sup>。但因为我们只考虑整数指数的问题实例，
前面这个办法只对偶数 n 有效。如果 n 是奇数，我们必须使用偶指数规则计算 a<sup>n-1</sup>,
然后把结果乘以 a。    

这样该算法的复杂度为 θ(logn)。    

感觉减治法就是把方案一致减下去，然后再简单地把结果合起来。分治法的话，好像在合并的时候要进行
很多复杂的操作。   

## 4.2 拓扑排序

考虑五门必须课的一个集合{C1, C2, C3, C4, C5}，一个在校的学生必须在某个阶段修完这几门
课程。可以按照任何次序学习这些课程，只要满足下面这些先决条件：C1 和 C2 没有任何先决条件，
修完 C1 和 C2 才能修 C3，修完 C3 才能修 C4，而修完 C3 和 C4 才能修 C5。这个学生
每个学期只能修一门肯城。这个学生应该按照什么顺序来学习这些课程。    

这种状况可以用一个图来建模，它的节点代表课程，有向边表示先决条件。就这个图来说，上面这个
问题其实就是：我们是否可以按照这种次序列出它的顶点，使得对于图中每一条边来说，边的起始顶点
总是排在边的结束顶点之前。这个问题称为 **拓扑排序**。可以对任意一个有向图提出这个问题，
但很容易发现，如果有向图具有一个有向的回路，该问题是无解的（为什么？？？）。因此，为了
使得拓扑排序成为可能，问题中的图必须是一个无环有向图。其实，为了使拓扑排序成为可能，
无环有向图不仅是必要条件，而且是充分条件。也就是说，如果一个图没有回路，对它来说，拓扑
排序是有解的。    

![class-select](https://raw.githubusercontent.com/temple-deng/markdown-images/master/algorithm/class-select.png)   

有两种算法可以用来解决拓扑排序的问题。第一个算法是深度优先查找的一个简单应用：执行一次
DFS 遍历，并记住顶点变成死端（即退出遍历栈）的顺序。将该次序反过来就是拓扑排序的一个解。   

第二种算法基于减治技术的一个直接实现：不断地做这样一件事，在余下的有向图中求出一个源，
它是一个没有输入边的顶点，然后把它和所有从他出发的边都删除。顶点被删除的次序就是拓扑排序的
一个解。   

## 4.3 生成组合对象的算法

### 4.3.1 生成排列

我们从排列开始，为了简单起见，假设需要对元素进行排列的集合是从 1 到 n 的简单整数集合。
为了使它更具有一般性，可以把它们解释为 n 个元素集合 {a1, ..., an} 中元素的下标。对于
生成 {1, ..., n} 的所有 n! 个排列的问题，减一技术有什么好建议的呢？该问题的规模减一
就是要生成所有 (n-1)! 个排列。假设这个较小的问题已经解决了，我们可以把 n 插入 n-1 个
元素的每一种排列中的 n 个可能位置中去，来得到较大规模问题的一个解。    

## 4.4 减常因子算法

### 4.4.1 折半查找

略。   

### 4.4.2 假币问题

在 n 枚外观相同的硬币中，有一枚是假币。在一架天平上，我们可以比较任意两组硬币。也就是说，
通过观察天平是右倾、左倾还是停在当中，我们可以判断出两组硬币重量是否相同。已知假币较轻。   

这里说这个问题的意思是，如果我们在比较的时候将硬币分 3 堆，效率要比 2 堆更好。   

### 4.4.3 约瑟夫问题

这里这样描述这个问题，1-n 共 n 个人，编号从 1 开始，假设一直消去编号为 2 的人。    

把奇数 n 和偶数 n 的情况分开来考虑会比较方便一些。如果 n 为偶数，也是说 n = 2k，对整个
圆圈处理第一遍之后，生成了同样问题的规模减半的实例。它们的唯一差别是位置的编号。例如，一个
初始位置为 3 的人在第 2 轮会处在 2 号位置上，依次类推。很容易发现，为了得到一个人的初始
位置，我们只需要将它的新位置乘 2 再减 1，也就是：   

J(2k) = 2J(k) - 1     

然后考虑 n 为奇数的情况，也就是 n = 2k+1。第一轮消去了所有偶数位。如果我们把紧接着消去的位置
1 上的人也加进来，我们留下一个规模为 k 的实例。这里，为了得到与新的位置编号相对应的初始位置
编号，我们必须把新的位置编号乘 2 再加 1，因此，对于奇数 n，有：   

J(2k + 1) = 2J(k) + 1     

## 4.5 减可变规模算法

### 4.5.1 计算中值和选择问题

选择问题是求一个 n 个数列表的第 k 个最小元素的问题。     

在不使用排序的情况下，可以使用 **划分**(partition) 的思路。有两种主要的划分算法，这里讨论
Lomuto 划分。这个划分好像就是单路快排的那种划分方法。另一种划分好像就是双路快排的思路。   

# 第 5 章 分治法

先略。    

# 第 6 章 变治法

本章讨论一组设计方法，它们都基于变换的思想。我们把这种通用技术称为 **变治法**，因为这些
方法都是分成两个阶段工作的。首先，在“变”的阶段，出于这样或者那样的原因，把问题的实例变
得更容易求解。然后，在第二阶段或者说“治”的阶段，对实例进行求解。   

根据我们对问题实例的变换方式，变治思想有 3 种主要的类型：   

+ 变换为同样问题的一个更简单或者更方便的实例 —— 我们称之为 **实例化简**
+ 变换为同样实例的不同表现 —— 我们称之为 **改变表现**
+ 变换为另一个问题的实例，这种问题的算法是已知的 —— 我们称之为 **问题化简**    

## 6.1 预排序

下面的 3 个例子说明了预排序的思想：   

1. **检验数组中元素的唯一性**   

使用蛮力法对数组中所有的元素进行比较，直到找到两个相等的元素，或者所有的元素对都已比较完毕。
它的最差效率为 O(n^2)。   

换一种做法，可以先排序，然后只检查连续元素。复杂度方面，排序至少要 O(nlogn)，后面的检查要 O(n)。
因此最后的效率大约是 O(nlogn)。    

2. **模式计算**     

在给定的数字列表中最经常出现的一个数值称为 **模式**。例如，对于 5,1,5,7,6,5,7 来说，
模式是 5（如果若干个不同的值都是最经常出现的，它们中的任何一个都可以看做模式）。   

这个问题其实用个 Map 的话，复杂度最差也就是个 O(n) + O(n) = O(n)。    

书上给的解法是，先排序，这样所有相等的数值都会邻接在一起。要求出模式，我们只需要求出在该有序
数组中邻接次数最多的等值元素即可。    

那复杂度就是 O(nlogn) + O(n) = O(nlogn)。     

3. **查找问题**   

略。     

# 第 7 章 时空权衡

这个思想是对问题的部分或全部输入做预处理，然后将获得的额外信息进行存储，以加速后面问题的求解。
我们把这个方法称为 **输入增强**，这些算法是以它为基础的：   

+ 计数排序
+ Boyer-Moore 字符串匹配算法和霍司普尔提出的简化版本    

其他采用空间换时间权衡思想的技术简单地使用额外空间来实现更快和更方便的数据存取。我们把这个方法
称为 **预构造**。这个名字强调了这种空间换时间权衡技术的两个方法：所讨论的问题在实际处理以前
就做过某些处理了，但是输入增强技术不同，这个技术只涉及存储结构：   

+ 散列
+ 以 B 树作索引

还有一种和空间换时间权衡思想相关调度算法设计技术：动态规划。这个策略的技术是把给定问题中
重复子问题的解记录在表中，然后求得所讨论问题的解。   

## 7.2 字符串匹配中的输入增强技术

### 7.2.1 Horspool 算法

作为一个例子，考虑在一个文本中查找模式 BARBER。从模式的最后一个 R 开始从右向左，我们比较模式
和文本中的相应字符对。如果模式中所有的字符都匹配成功，就找到了一个匹配的字符串，就可停止
查找了。如果还希望查找同样模式的另一个匹配，就继续查找。    

如果遇到了一对不匹配字符，我们需要把模式右移。很明显，如果不存在错过文本中一个匹配子串的风险，
我们希望移动的幅度尽可能地大。假设文本中，对齐模式最后一个字符的元素是字符 c，Horspool 算法
根据 c 的不同情况来确定移动的距离，无论 c 是否和模式的最后一个字符相匹配。    

注意上面的意思，c 是我们开始匹配的时候的文本中从右向左的第一个字符。    

一般来说，会存在下面 4 种情况。   

+ 情况 1：如果模式中不存在 c（注意是在模式中压根不存在这个字符），模式安全移动的幅度就是它的
全部长度，这也好理解，因为这个模式里面没一个元素和这个 c 匹配，那直接整体跳过就好
+ 情况 2：如果模式中存在 c，但它不是模式的最后一个字符（在我们的例子中，c 就是字母 B），移动
时应该把模式中最右边的 c 和文本中的 c 对齐。     

```
s0, ....    B       .... s(n-1)
           !=
 B A R B E  R
     B A R  B E R
```     

+ 情况 3：如果 c 正好是模式中的最后一个字符，但是在模式的其他 m-1 个字符中不包含 c，移动的
情况类似情况 1，移动的幅度等于模式的全部长度 m。     

```
s0 ...    M   E   R    ... s(n-1)
         !=   =   =   
  L E A  D    E   R
                    L  E  A  D  E  R
```    

这里也好理解，就这一个字符，除了末尾部分其他都没了，那只要一遇到不匹配就可以整体移动了。    

+ 情况4：最后，如果 c 正好是模式中最后一个字符，而且在模式的前 m-1 个字符中也包含 c，移动
的情况就类似于情况 2，移动时应该把模式中前 m-1 个字符中的 c 和文本中的 c 对齐     

```
s0 ...      A   R    ... s(n-1)
           !=   =
  R E O R D E   R
        R E O   E D E R
```    

我们可以预先算出每次移动的距离并把它们存在表中。这个表是以文本中所有可能遇到的字符为索引的，
对于一个自然语言的文本来说，这些字符串包括空格、标点符号和其他一些特殊字符。我们将移动的距离
填入表中的单元格，具体来说，对于每一个字符 c，我们可以用以下公式算出移动距离：    

t(c) = 模式的长度 m（如果 c 不包含在模式的前 m-1 个字符中）
     = 模式的前 m-1 个字符中最右边的 c 到模式中最后一个字符的距离（在其他情况下）    

例如，对于模式 BARBER，除了 E, B, R, A 的单元格分别为 1,2,3,4 之外，其他的单元格都
等于 6.     

这里有一个简单的算法用来计算移动表中的每个单元格的值。初始时把所有的单元格都置为模式的长度 m，
然后从左到右扫描模式，将下列步骤重复 m-1 遍：对于模式中的第 j 个字符（0 &lt;= j &lt;= m-2)，
将它在表中的单元格改写为 m - 1 - j，这是该字符到模式右端的距离。注意，因为该算法是从左到右扫描
模式，一个字符的最后一次改写一次是在该字符最右边一次出现的时候。    

```
ShiftTable(P[0..m-1])

for j <- 0 to size-1 do Table[i] <- m
for j <- 0 to m-2 do Table[P[j]] <- m-1-j
return Table
```    

有了这个表就好了，我们匹配的时候一遇到不匹配的字符，直接按当前文本的最后一个字符在表中的值，
进行偏移。     

```js
function Horspool(text, pattern) {
  const {map, ok} = buildTable(text, pattern);
  if (!ok) {
    return -1;
  }

  const tLen = text.length;
  const pLen = pattern.length;
  for (let i = pLen-1; i < tLen; ) {
    let j = pLen-1;
    for (; j >= 0; j--) {
      if (text[i-pLen+j+1] !== pattern[j]) {
        i = i + map.get(text[i]);
        break;
      }
    }
    if (j === -1) {
      return i+1-pLen;
    }
  }
  return -1;
}

function buildTable(text, pattern) {
  const map = new Map();
  const tLen = text.length;
  const pLen = pattern.length;

  for (let i = 0; i < tLen; i++) {
    map.set(text[i], pLen);
  }

  for (let i = 0; i < pLen-1; i++) {
    if (!map.has(pattern[i])) {
      // 可以提前终止掉
      return {
        map: null,
        ok : false
      };
    }
    map.set(pattern[i], pLen-1-i);
  }
  return {
    map,
    ok: true
  };
}
```    

Horspool 算法的最差效率属于 O(nm)，但对于随机文本来说，它的效率是属于 O(n)的。而且，
虽然效率类型相同，但平均来说，Horspool 算法显然要比蛮力算法块很多。    

### 7.2.2 Boyer-Moore 算法

如果模式最右边的字符和文本中的相应字符 c 所做的初次比较失败了（这里没说明白失败了是怎么
个失败了），该算法和 Horspool 算法所做的操作完全一致（这里其实考不考虑这种情况并不重要）。
我们前面曾经解释过如何事先计算好一张表，这时，它也会按照从这张表中取出的字符个数将模式
向右移动相应的距离。   

这个不同的地方都算法移动的解释都各不相同，简单来说，Boyer-Moore 使用了两种启发式的策略
来在不匹配的时候决定右移的距离，分别是坏字符移动和好后缀移动。而由于好后缀移动不好理解
又不好实现，因此很多人简化了这一算法，像上面的 Horspool 算法就只用到了坏字符移动策略。   

然而，在遇到一个不匹配的字符之前，如果已经有 k(0 &lt; k &lt; m)个字符成功匹配了，这两个
算法的操作是不同的。    

在这种情况下，Boyer-Moore 算法会参考两个数值来确定移动的距离。第一个数值是由文本中的一个
字符 c 确定的，它导致了模式中的相应字符和它不匹配。因此我们把它称为 **坏符号移动**(bad-symbol shift)。
导致这种移动的原因和导致 Horspool 算法移动的原因是一样的。如果 c 不在模式中，我们把模式
移动到正好跳过这个字符的位置。为方便起见，可以用公式 t(c) - k 来计算移动的距离，其中 t(c)
是 Horspool 算法用到的预先算好的表中的单元格，而 k 是成功匹配的字符个数。    

这种情况下 t(c) = m，k 是已经匹配的字符数，那左边未匹配的就是 t(c) - k。    

例如，如果我们正在某个文本中查找模式 BARBER，在成功匹配了最后两个字符以后，却无法匹配
文本中的字母 S，我们可以把模式移动 t(S) - 2 = 6 - 2 = 4 个位置。    

如果不匹配字符 c 出现在模式中，而且 t(c) - k &gt; 0，这个公式也是可用的。例如，如果我们
正在某个文本中查找模式 BARBER，在成功匹配了最后两个字符以后，却无法匹配文本中的字母 A，
我们可以把模式移动 t(A) - 2 = 4 - 2 = 2个位置。   

如果 t(c) - l &lt;= 0，我们显然不希望把模式移动 0 个或者负数个位置。我们宁可回到蛮力的
思路上，简单地把模式向右移动一个字符。   

总之，Boyer-Moore 算法是这样计算坏符号移动 d1 的：如果这个数值是正数，它等于 t(c) - k。
如果是 0 或者负数，则为 1，这句话可以用下面的紧凑公式来表达：   

d1 = max{t(c) - k, 1}    

这里其实还有另外一种对坏字符移动的解释，其实每次匹配时第一个遇到的不匹配的字符就是
坏字符，然后这时我们后移的距离：   

后移位数 = 坏字符的位置 - 模式中坏字符上一次出现位置。    

如果坏字符不在模式之中，则上一次出现位置为 -1。   

坏字符的位置是指当次匹配时，字符在文本中的索引位置，而模式中坏字符上一次出现的位置，应该
是模式左边中还没有匹配的部分中最后一次出现的位置。即一个是字符在文本中的索引，一个是在
模式中的索引，两者一减，就可以得出两者前的空当，然后让两者对齐。   

这样看上面两种说法最后给出的移位效果好像还不一样。。。，但是好像第一种方案中给出的坏字符
表比较好构造，因为第二种里面外面不好计算模式中坏字符上一次出现的位置。    

第二种移动是由模式中最后 k &gt; 0 个成功匹配的字符确定的。我们把模式的结尾部分叫做模式
的长度为 k 的后缀，记作 suff(k)。相应地，我们把这种类型的移动称为 **好后缀移动**(good-suffix shift)。
在坏符号移动表中，我们是根据单独的字符 c 来填充表格的，而在好后缀移动表中，我们是根据
模式后缀的长度 1, ..., m-1 来分别填充表格的。   

好后缀规则的移动规则为：   

后移位数 = 好后缀的位置 - 模式中的上一次出现位置    

举例来说，如果字符串 ABCDAB 的后一个 AB 是好后缀。那么它的位置是 5（从 0 开始计算，取
最后的 B 的值），在模式中上一次出现的位置是 1（第 1 个 B的位置），所以后移 5-1 = 4.    

这时的两个索引都是在模式中的。   

如果好后缀有多个，则除了最长的那个好后缀，其他好后缀的上一次出现位置必须在头部。比如，
假定2 BABCDAB 的好后缀是 DAB, AB, B，请问这时好后缀的上一次出现位置是什么？回答是，
此时采用的好后缀是 B，它的上一次出现位置是头部，即第 0 位。这个规则也可以这样表达，如果
最长的那个好后缀只出现一次，则可以把搜索词改写成如下形式进行位置计算 (DA)BABCDAB，即
虚拟加入最前面的 DA。    

Boyer-Moore 算法的基本思想是，每次后移这两个规则之中的较大值。   

# 第 8 章 动态规划

如果问题是由交叠的子问题构成的，我们就可以用动态规划技术来解决它。一般来说，这样的子问题
出现在对给定问题求解的递推关系中，这个递推关系中包含了相同类型的更小子问题的解。动态规划
法建议，与其对交叠的子问题一次又一次地求解，还不如对每个较小的子问题只求解一次并把结果
记录在表中，这样就可以从表中得出原始问题的解。    

虽然动态规划法的直接应用也可以直接解释成一种特殊类型的空间换时间权衡技术，但有时候一个动态
规划算法经过改进可以避免使用额外的空间。    

由于动态规划的大多数应用都是求解最优化问题，因此我们需要指出这类应用中一个一般性法则。
称为 **最优化法则**。该法则认为最优化问题任一实例的最优解，都有由其子实例的最优解构成
的。最优化法则在大多数情况下是成立的，尽管也有少数情况例外。     

## 8.1 三个基本例子

1. **币值最大化问题**    

给定一排 n 个硬币，其面值均为正整数 c1, c2, ..., cn，这些整数并不一定两两不同。请问如何
选择硬币，使得其在原始位置互不相邻的条件下，所选硬币的总金额最大。    

上述最大可选金额用 F(n) 表示。为了得到 F(n) 的递推关系，我们将所有可行的选择划分为两组：
包括最后一枚硬币和不包括最后一枚硬币的。第一组中，可选硬币的最大金额等于 cn + F(n-2)，
另一组中，可选的最大金额等于 F(n-1)。因此，我们得到符合初始条件的递推方程：   

F(n) = max{ cn + F(n-2), F(n-1)},  n &gt; 1   
F(0) = 0, F(1) = c1     

```go
func CoinRow(coin []int) int {
  // F[i] 存放 i 枚硬币下的最大面值
	F := make([]int, len(coin) + 1)

	F[0] = 0
	F[1] = coin[0]

	for i := 2; i <= len(coin); i++ {
		F[i] = int(math.Max(float64(coin[i-1] + F[i-2]), float64(F[i-1])))
	}

	return F[len(coin)]
}
```    

注意这其实是个自底向上的算法。    

2. **找零问题**    

需找零的金额为 n，最少用多少面值 d1 &lt; d2 &lt;...&lt; dm 的硬币，d1 = 1,每种面值的
硬币数量无限。     

设 F(n) 为总金额为 n 的数量最少的硬币数目，方便起见定义 F(0) = 0。获得 n 的途径只能是：
在总金额为 n - dj 的一堆硬币上加入一个面值为 dj 的硬币，其中 j=1,2,...,m，并且 n &gt;= dj。
因此我们只需要考虑所有满足上述要求的 dj 并选择使得 F(n-dj) + 1最小的 dj 即可。由于 1 是
常量，我们显然可以先找出最小的 F(n-dj)，然后加 1 即可。因此我们得到了以下 F(n) 的递推公式：   

F(n) = min{F(n-dj) + 1},  n &gt; 0, n &gt;= dj   
F(0) = 0    

```go
func ChangeMaking(d []int, n int) int {
	f := make([]int, n+1)

	f[0] = 0

	// i 是面额，f[i] 是面额为 i 时的最优解问题
	// d[0] = 1 确保了问题一定是有解的
	for i := 1; i <= n; i++ {
		// 这里最大值就不取无穷了
		temp := math.MaxInt32
		j := 0
		for ; j < len(d) && i >= d[j]; j++ {
			temp = int(math.Min(float64(f[i-d[j]]), float64(temp)))
		}
		f[i] = temp+1
	}
	return f[n]
}
```    

## 8.2 背包问题和记忆功能

### 8.2.1 背包问题

给定 n 个重量为 w1, ..., wn，价值为 v1, ..., vn 的物品和一个承重量为 W 的背包，求这些
物品中最有价值的一个子集，并且要能够装到背包中。在这里假设所有的重量和背包承重量是正整数，
而物品的数量不必是整数，卧槽，这个不必是整数要怎么处理，半个半个放？     

为了设计一个动态规划算法，需要推导出一个递推关系，用较小子实例的解的形式来表示背包问题的实例
的解。让我们来考虑一个由前 i 个物品定义的实例，物理的重量分别为 w1, ..., wi, 价值分别为
v1, ..., vi，背包的承重量为 j。设 F(i, j) 为该实例的最优解的物品总价值。可以把前 i 个
中能够放进承重量为 j 的背包中的子集分成两个类别：包括第 i 个物品的子集和不包括第 i 个物品的
子集。然后有了下面的结论：     

1. 根据定义，在不包括的第 i 个物品的子集中，最优子集的价值是 F(i-1, j)
2. 在包括第 i 个物品的子集中，最优子集是由该物品和前 i-1 个物品中能够放进承重量为 j-wi 的
背包的最优子集组成，这种最优子集的总价值等于 vi+F(i-1, j-wi)    

因此，在前 i 个物品中最优解的总价值等于这两个价值中的较大值。当然，如果第 i 个物品不能放进
背包，从前 i 个物品选出的最优子集的总价值等于从前 i-1 个物品中选择出的最优子集的总价值，这就
导致了下面的递推式：   

F(i, j) = max{F(i-1, j), vi + F(i-1, j-wi)},    j - wi &gt;=0   
          F(i-1, j),   j - wi &lt; 0    

我们可以很容易地如下定义初始条件：    

但 j &gt;= 0 时，F(0, j) = 0, 当 i &gt;= 0 时，F(i, 0) = 0    

我们的目标是求 F(n, W).     

```js
// 自底向上的求解方案
function knapsack(w, v, W) {
  const n = w.length;
  var arr = Array(n+1);

  // 建立一个 n+1 * W+1 的矩阵
  for (let i = 0; i <= n; i++) {
    arr[i] = Array(W + 1);
  }

  for (let i = 0; i <= W; i++) {
    arr[0][i] = 0;
  }

  for (let i = 0; i <= n; i++) {
    arr[i][0] = 0;
  }

  for (let j = 1; j <= W; j++) {
    for (let i = 1; i <= n; i++) {
      if (j - w[i-1] < 0) {
        arr[i][j] = arr[i-1][j];
      } else {
        arr[i][j] = Math.max(arr[i-1][j], arr[i-1][j-w[i-1]] + v[i-1]);
      }
    }
  }
  return arr[n][W];
}
```   

### 8.2.2 记忆化

动态规划方法所涉及问题的解，满足一个用交叠的子问题来表示的递推关系。直接自顶向下对这样一个递推
式求解导致一个算法要不止一次地解公共的子问题，因此效率是非常低的。另一方面，经典的动态规划
方法是自底向上的：它用所有较小子问题的解填充表格，但是每个子问题只解一次。这种方法无法令人
满意的一面是，在求解给定问题时，有些较小子问题的解常常不是必需的。由于这个缺点没有在自顶向下
法中表现出来，所以我们很自然地希望把自顶向下和自底向上方法的优势结合起来。我们的目标是得到
这么一种方法，它只对必要的子问题求解并且只解一次。这个方法是存在的，它是以 **记忆功能**
为基础的。    

该方法用自顶向下的方式对给定的问题求解，但还需要维护一个类似自底向上动态规划算法使用的表格。
一开始的时候，用 null 符号初始化所有的单元格，用来表示没有计算过。之后，一旦需要计算一个
新的值，该方法先检查表中相应的单元格。如果该单元格不是 null，就从表中取值，否则，就使用
递归调用进行计算，然后把返回的结果记录在表中。    

```js
function knapsack(w, v, W) {
  var n = w.length;
  var arr = Array(n+1);

  for (let i = 0; i <= n; i++) {
    arr[i] = Array(W+1);
  }

  for (let i = 0; i <= n; i++) {
    arr[i][0] = 0;
  }

  for (let i = 0; i <= W; i++) {
    arr[0][i] = 0;
  }

  (function knap(i, j) {
    if (arr[i][j] !== undefined) {
      return arr[i][j];
    }

    if (j - w[i-1] < 0) {
      arr[i][j] = knap(i-1, j);
      return arr[i][j];
    } else {
      arr[i][j] = Math.max(knap(i-1, j), knap(i-1, j - w[i-1]) + v[i-1]);
      return arr[i][j];
    }
  })(n, W);

  console.log(arr);
  return arr[n][W];
}
```    

# 第 9 章 贪婪技术

尽管实际上这个方法只能应用于最优问题，但计算机科学家把它当作一种通用的设计技术。贪婪法
建议通过一系列步骤来构造问题的解，每一步对目前构造的部分分解做义工扩展，直到获得问题的
完整解为止。这个技术的核心是，所做的每一步选择都必须满足以下条件：   

+ **可行的**：即它必须满足问题的约束
+ **局部最优**：它是当前步骤中所有可行选择中最佳的局部选择
+ **不可取消**：即选择一旦做出，在算法的后面步骤中就无法改变了    

这些要求对这种技术的名称做出了解释：在每一步中，它要求“贪婪”地选择最佳操作，并希望通过一
系列局部的最优选择，能够产生一个整个问题的最优解。    

# 第 11 章 算法能力的极限

## 11.3 P, NP 和 NP 完全问题

在研究问题的计算复杂性时，计算机科学家首先考虑的都是一个给定的问题是不是能够用某些算法
在多项式的时间内求解。    

> 定义：如果一个算法的最差时间效率属于 O(p(n))，我们说该算法能够在多项式的时间内对问题
求解，其中 p(n) 是问题输入规模的一个多项式函数。我们把可以在多项式时间内求解问题称为是
**易解的**，而不能在多项式的时间内求解的问题则称为 **难解的**。    

### 11.3.1 P 和 NP 问题

非正式地来说，我们可以把那些能够在多项式时间内求解的问题当做计算机科学家所说的 P 集合。
在一个更正式地定义中，只有 **判定问题** 才属于 P，也就是那些能够回答是或否的问题。   

> 定义：P 类问题一般是能够用（确定性的）算法在多项式的时间内求解的判定问题。这种问题类型
也称为多项式类型。    

但是也不是每一个判定问题都能在多项式的时间内求解。   

有许多的重要问题，我们既没有找到他们的多项式类型算法，也无法证明这样的算法不存在：   

+ **哈密顿回路问题**：确定一个给定的图中是否包含一个哈密顿回路（一条起止于相同顶点的路径，
并且只经过其他所有顶点一次）
+ **旅行商问题**：对于相互之间距离为已知正整数的 n 座城市，求最短的漫游路径（求一个权重
为正整数的完全图的最短哈密顿回路）
+ **背包问题**：对于 n 个重量和价值都为给定正整数的物品和一个承重量为给定正整数的背包，
求这些物品中一个最有价值的子集，并且能够装到背包中。
+ **划分问题**：给定 n 个正整数，判断是否能够把它们划分成两个不相等的子集，并且和相等
+ **装箱问题**：给定 n 个物品，它们的大小都是不超过 1 的有理数，把它们装进数量最少的
大小为 1 的箱子中。
+ **图的着色问题**：对于一个给定的图，求使得任何两个相邻顶点的颜色都不同时需要分配给图
顶点的最少颜色数量。    

# 第 12 章 超越算法能力的极限

回溯法和分支界限法都是以构造一颗 **状态空间树** 为基础的，树的节点反映了对一个部分解所做
的特定选择。如果可以保证，节点子孙所对应的选择不可能得出问题的一个解，两种技术都会立即
停止处理这个节点。两种技术的区别在于他们能够处理的问题类型不同。分支界限法只能应用于最优
问题，因为它基于针对一个问题的目标函数，计算其可能值的边界。回溯法并不受这种要求的制约，
但在大多数的情况下，它处理的是非优化问题。回溯法和分支界限法的另一个区别在于他们生成状态
空间树的节点的顺序不同。对于回溯法来说，它的树的生长顺序常常是深度优先的，分支界限法可以
根据多种规则生成节点。      

## 12.1 回溯法

回溯法是穷举查找技术的一个更聪明的变化形式。它的主要思想是每次只构造解的一个分量，然后按照
下面的方法来评估这个部分构造解。如果一个部分构造解可以进一步构造而不会违反问题的约束，我们就
接受对解的下一个分量所做的第一个合法选择。如果无法对下一分量进行合法的选择，就不必对剩下
的任何分量再做任何选择了。在这种情况下，该算法进行回溯，把部分构造解的最后一个分量替换为它
的下一个选择。     

通过对所做的选择构造一颗所谓的 **空间状态树**，我们很容易实现这种处理。树的根代表了在查找
解之前的初始状态。树的第一层节点代表了对解的第一个分量所做的选择，第二层节点代表了对解的
第二个分量所做的选择，以此类推。如果一个部分构造解仍然有可能导致一个完整解，我们说这个部分
解在树中的相应节点是 **有希望的**；否则，我们说它是 **没希望的**。叶子则要么代表了没希望的
死胡同，要么代表了算法找到的完整解。在大多数情况下，一个回溯算法的状态空间树是按照深度优先的
方式来构造的。如果当前节点是有希望的，通过向部分解添加下一个分量的第一个合法选择，就生成了节点
的一个子女，而处理也会转向这个子女节点。如果当前节点变得没希望了，该算法回溯到该节点的父母，
考虑部分解的最后一个分量的下一个可能选择。如果这种选择不存在，它再回溯到树的上一层，依次类推。    


### 12.1.1 n 皇后问题

这个问题要求把 n 个皇后放在一个 n * n 的棋盘上，使得任何两个皇后都不能相互工具，即它们不能
同行，不能同列，也不能位于同一条对角线上。对于 n = 1，问题的解很简单，而且很容易看出对于
n = 2 和 n = 3 来说，这个问题是无解的。      

因为每个皇后都必须分别占据一行，所以我们需要做的就是为每个皇后分配一列。     

对于任何一个 n &gt;= 4 的 n 皇后问题都可以在线性时间内求解。     

### 12.1.3 子集和问题

求 n 个正整数构成的一个给定集合 A = {a1, ..., an} 的子集，子集的和要等于一个给定的正整数 d。
把集合元素按照升序排列会带来不少的方便。     

### 12.1.4 一般性说明

从更一般的角度来看，大多数回溯算法都满足下面的描述。某个回溯算法的一个输出可以看做一个 n 元祖
(x1, x2, ..., xn)，其中每一个坐标 xi 都是某个有限线性有序集 Si 的一个元素。例如，对于 n
皇后问题，每一个 Si 都是从 1 到 n 的整数（列编号）构成的一个集合。这个元祖可能需要满足一些
额外的约束（例如，在 n 皇后问题中的相互不攻击要求）。取决于具体的问题，所有解元祖的长度可以是
相等的（n 皇后问题和哈密顿回路问题），也可以是不等的（子集和问题）。一个回溯算法会明确地或者
隐含地生成一颗状态空间树，树中的节点代表了由算法的前面步骤所定义的前 i 个坐标所组成的部分构造
元祖。如果这样一个元祖(x1, x2, ..., xi) 不是问题的一个解，该算法从 si+1 中找出下一个元素，
该元素不仅和 (x1, x2, ..., xn)值相容，而且和问题的约束相容，然后把这个元素加到元祖中，
作为元祖的第 i+1 个坐标，如果这样的元素不存在，该算法向后回溯，考虑 xi 的下一个值，以此
类推。    

```
Backtrack(X[1..i])
  // 输入：X[1..i] 确定了一个解的前面 i 个有希望的分量
  // 输出：代表问题解的所有元祖
  if X[1..i] 是一个解 write X[1..i]
    else  // 待完成
      for 和 X[1..i] 以及约束相容的每一个约束的每一个约束 x in Si+1 do
        X[i+1] <- x
        Backtrack(X[1..i+1])
```    

## 12.2 分支界限法

和回溯法相比，分支界限法需要两个额外的条件：    

+ 对于一颗状态空间树的每一个节点所代表的部分解，我们要提供一种方法，计算出通过个部分解繁衍出
的任何解在目标函数上的最佳值边界
+ 目前求得的最佳解的值     

如果可以得到这些信息，我们可以拿某个节点的边界值和目前求得的最佳解进行比较：如果边界值不能超越
目前的最佳解，这个节点就是一个没有希望的节点，需要立即终止，因为从这个节点生成的解，没有一个能
比目前已经得到的解更好。    

一般来说，对于一个分支界限算法的状态空间树来说，只要符合下面三种中的一种原因，我们就会终止
它在当前节点上的查找路径：    

+ 该节点的边界值不能超越目前最佳解的值
+ 该节点无法代表任何可行解，因为它已经违反了问题的约束
+ 该节点代表的可行解的子集只包含在一个单独的点（因此无法给出更多的选择）。在这种情况下，我们拿
这个可行解在目标函数上的值和目前求得的最佳解进行比较，如果新的解更好一些，就用前者替换后者。    

### 12.2.1 分配问题

分配问题要求把 n 项工作分配给 n 个人，并使总分配成本尽可能地小。    

