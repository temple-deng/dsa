# 第 1 章 绪论

## 1.3 重要的问题类型

+ 排序
+ 查找
+ 字符串处理
+ 图问题
+ 组合问题
+ 几何问题
+ 数值问题    

### 1.3.1 排序

排序使我们更容易求解和列表相关的问题。其中最重要的是查找问题：这就是为什么字典、电话簿和班级名册
都是拍好序的。同样原因，在很多其他领域的重要算法（例如几何算法和数据压缩）中，排序也被作为一个
辅助步骤。贪婪算法也要求有序的输入。    

### 1.3.2 查找

有很多查找算法可供选择，其中既包括直截了当的顺序搜索，也包括效率极高但应用受限的这班查找，还有
那些将原集合用另一种形式表示以方便查找的算法。   

### 1.3.3 图算法

基本的图算法包括图的遍历算法（如何能一次访问到网络中的所有节点）、最短路线算法（两个城市之间
的最佳路线是哪条？）以及有向图的拓扑排序（一系列课程的预备课程是相互一致的，还是自相矛盾的？）。    

有一些图问题在计算上是非常困难的。其中最广为人知的恐怕要数旅行商问题和图填色问题了。**旅行商问题**
(traveling salesman problem, TSP) 就是要找出访问 n 个城市的最短路径，并且保证每个城市
只访问一次。**图填色问题** 就是要用最少种类的颜色为图中的顶点着色，并保证任何两个邻接顶点
的颜色都不同。这个问题源于若干应用，例如安排事务进度：如果用以边相连的顶点代表事务，当且
仅当独立事务无法排定同时发生时，图填色问题的解才能生成一张最优的日程表。   

### 1.3.4 组合问题

从更抽象的角度来看，旅行商问题和图着色问题都是 **组合问题** 的特例。有一些问题要求寻找一个
组合对象，例如一个排列、一个组合或者一个子集，这些对象能够满足特定的条件并具有我们想要的
特性，如价值最大化或成本最小化。    

一般说来，无论从理论角度还是实践角度来看，组合问题都是计算领域中最难的问题。这时出于以下原因。
第一，通常，随着问题规模的增大，组合对象的数量增长极快，即使是中等规模的实例，其组合的规模也
会达到不可思议的数量级。第二，还没有一种已知算法能在可接受的时间内，精确地解决绝大多数这类
问题。而且，大多数计算机科学家认为这样的算法是不存在的。但这个猜想即没被证实，也没被证伪。    

有些组合问题用高效的算法求解，但我们应该把它们当作幸运的例外。这些例外中就包含前面提到的
最短路径算法。    

## 1.4 基本数据结构

### 1.4.1 图

几个概念：   

+ 有向和无向
+ 有权和无权
+ 完全图
+ 邻接表
+ 邻接矩阵
+ 路径
+ 简单路径
+ 连通性和连通分量
+ 邻接
+ 自环
+ 平行边    

**状态空间树**(state-space tree)，它强调了两种重要的算法设计技术：**回溯** 和 **分支界限**。   

顶点 v 的深度是从根到 v 的简单路径的长度。树的高度是从根到叶节点的最长简单路径的长度。    

# 第 2 章 算法效率分析

## 2.3 非递归算法的数学分析

分析非递归算法效率的通用方案：   

1. 决定用哪个（哪些）参数表示输入规模
2. 找出算法的基本操作（作为一个规律，它总是位于算法的最内层循环中）
3. 检查基本操作的执行次数是否只依赖于输入规模。如果它还依赖与一些其他的特性，则最差效率、平均
效率以及最优效率需要分别研究
4. 建立一个算法基本操作执行次数的求和表达式
5. 利用求和运算的标准公式和法则来建立一个操作次数的闭合公式，或者至少确定它的增长次数   

@TODO 求和公式

## 2.4 递归算法的数学分析

分析递归算法时间效率的通用方案：   

1. 决定用哪个（哪些）参数作为输入规模的度量标准
2. 找出算法的基本操作
3. 检查一下，对于相同规模的不同输入，基本操作的执行次数是否可能不同。如果有这种可能，则必须
对最差效率、平均效率以及最优效率做单独研究
4. 对于算法基本操作的执行次数，建立一个递归关系以及相应的初始条件
5. 解这个递归式，或者至少确定它的解的增长次数    

@TODO 递推关系   

## 2.5 计算第 n 个斐波那契数

斐波那契数列可以用一个简单的递推式和两个初始条件来定义：   

当 n &gt; 1 时，F(n) = F(n-1) + F(n-2)    
    F(0) = 0，  F(1) = 1    

首先，先给出一个求解第 n 个斐波那契数的明确的公式。如果试着应用反向替换法来接递归公式。我们将
无法得到一个容易识别的模式。但我们可以改用另外一个定理。这个定理描述了如何求解
**带常系数的齐次二阶线性递推式**。    

ax(n) + bx(n-1) + cx(n-2) = 0    

其实,a, b, c 都是固定的实数，称为该递推式的系数，x(n) 是一个待解的未知数列的一般项。将该定理
应用到一个具有给定初始条件的递推关系中，我们将获得下列公式：    

@TODO

# 第 3 章 蛮力法

**蛮力法**(brute force) 是一种简单直接地解决问题的方法，常常直接基于问题的描述和所涉及的
概念定义。    

虽然巧妙和高效的算法很少来自于蛮力法，但我们不应该忽略它作为一种重要的算法设计策略的地位。第一，
和其他某些策略不同，我们可以应用蛮力法解决广阔领域的各种问题。实际上，它可能是唯一一种几乎
什么问题都能解决的一般性方法。第二，对于一些重要的问题来说，蛮力法可以产生一些合理的算法，
它们多少具备一些实用价值，而且不必限制实例的规模。第三，如果要解决的问题实例不多，而且蛮力法
可以用一种能够接受的速度对实例求解，那么，设计一个更高效算法所花费的代价很可能是不值得的。    

## 3.1 选择排序和冒泡排序

选择排序略了。   

冒泡排序比较表中的相邻元素，如果它们是逆序的话就交换它们的位置。重复多次以后，最终，最大的元素
就“沉到”列表的最后一个位置。第二遍操作将第二大的元素沉下去。这样一直做，直到 n - 1 遍以后，
该列表就排好序了。    

```go
func BubbleSort(arr []int) {
	length := len(arr)

	for i := 0; i < length-1; i++ {
		for j := 0; j < length-1-i; j++ {
			if arr[j] > arr[j+1] {
				swap(arr, j, j+1)
			}
		}
	}
}
```   

这里仔细分析一下两层循环的临界条件，外层循环每迭代一次，都有一个数下沉到最后，那么理论上一共
需要迭代 n 次，但是介于只剩一个数的时候其实就已经不用迭代了，因此实际上只用迭代 n-1 次，因此
i 的最大可取值为 n-2。内层循环，每次迭代的范围是从 0 到当前未排序的数组的倒数第二个元素，即
n-2-i。    

## 3.2 顺序查找和蛮力字符串匹配

顺序查找略。   

蛮力字符串匹配：   

```js
function BruteForceStringMatch(text, pattern) {
  const tLen = text.length;
  const pLen = pattern.length;

  // 注意这里临界值
  for (let i = 0; i <= tLen-pLen; i++) {
    for (let j = 0; j < pLen; j++) {
      if (text[i+j] !== pattern[j]) {
        break;
      }
    }
    if (j === pLen) {
      return i;
    }
  }
  return -1
}
```   

在移动模式之前，算法可能要做足 m 次比较（m 是 pattern 的长度），而 n-m+1 次尝试的每一次
都可能会遇到这种情况。因此在最坏的情况下，该算法属于 O(mn)。然而，对于在自然语言文本中
查找词的典型问题，我们可以认为大多数移动都发生在很少的几次比较之后。所以，该算法的平均效率
应该比最差效率好的多。事实上也是这样，在查找随机文本时，它能够显示出线性的效率，即 O(n)。    

## 3.4 穷举查找

许多重要的问题要求在一个复杂度随实例规模指数增长的域中，查找一个具有特定属性的元素。无论是
明智还是暗指，一般来说，这种问题往往涉及组合对象，例如排列、组合以及一个给定集合的子集。许多
这样的问题都是最优问题：它们要求找到一个元素，能使某些期望的特性最大化或最小化，例如路径的
长度或分配的成本。    

对于组合问题来说，**穷举查找** 是一种简单的蛮力方法。它要求生成问题域中的每一个元素，选出
其中满足问题约束的元素，然后再找出一个期望元素。    

### 3.4.1 旅行商问题

这个问题要求找出一条 n 个给定的城市间的最短路径，使我们在回到出发的城市之前，对每个城市都
只访问一次。这个问题可以很方便地用加权图来建模，也就是说，用图的顶点代表城市，用边的权重
表示城市间的距离。这样该问题就可以表述为求一个图的最短 **哈密顿回路** 问题。我们把哈密顿
回路定义为一个对图的每个顶点都只穿越一次的回路。    

很容易看出，哈密顿回路可以定义为 n+1 个相邻顶点的一个序列，其中，第一个和最后一个顶点是
相同的，而其他 n-1 个顶点都是互不相同的。因此，可以通过生成 n-1 个中间城市的组合来得到
所有的旅行线路，计算这些线路的长度，然后求得最短的线路。   

### 3.4.2 背包问题

给定 n 个重量为 w1, w2, ..., wn，价值为 v1, v2, ..., vn 的物品和一个承重为 W 的背包，
求这些物品中一个最有价值的子集，并且要能够装到背包中。    

在这个问题中，穷举查找需要考虑给定的 n 个物品集合的所有子集，为了找出可行的子集，要计算出每个
子集的总重量，然后在它们中间找到价值最大的子集。因为一个 n 元素集合的子集数量是 2^n，所以
不论生成独立子集的效率有多高，穷举查找都会导致一个 Ω(2^n) 的算法。    

因此，不论对旅行商问题还是背包问题，穷举查找型算法对于任何输入都是非常低效率的。实际上，这两个
问题就是所谓的 **NP困难问题** 中最著名的例子。对于 NP 困难问题，目前没有已知的效率可以
用多项式来表示的算法。而且，大多数计算机科学家相信，这样的算法是不存在的。一些更复杂的方法
—— 回溯法和分支界限法使我们可以在优于指数级的效率下解决该问题的部分实例。    

## 3.5 深度优先查找和广度优先查找

在深度优先查找遍历的时候构造一个所谓的深度优先查找森林也是非常有用的。遍历的初始节点可以作为
这样

# 第 4 章 减治法

**减治法** 技术利用了一个问题给定实例的解和同样问题较小实例的解之间的某种关系。一旦建立了
这种关系，我们即可以从顶至下，也可以从底至上地运用该关系。虽然自顶向下会自然导致出递归算法，
但从本章的例子可以看出，最终还是非递归实现较好。自底向上版本往往是迭代实现的，从求解问题的一个
较小实例开始，该方法有时也称为 **增量法**。   

减治法有 3 种主要的变化形式：   

+ 减去一个常量
+ 减去一个常量因子
+ 减去的规模是可变的    

在 **减常量** 变化形式中，每次算法迭代总是从实例中减去一个相同的常量。一般来说，这个常量
等于 1。    

@TODO 图

作为一个例子，考虑指数问题 a<sup>n</sup> 的值，其中 a != 0, n 为非负整数，很明显，规模
为 n 的实例和规模为 n-1 的实例的关系，可由公式 a<sup>n</sup> = a<sup>n-1</sup> * a
来描述。所以函数 f(n) = a<sup>n</sup> 即可以用它的递归定义：    

```
f(n) = f(n-1) * a    // n > 0
     = a             // n = 0
```    

从顶至下地计算，也可以从底至上地把 a 自乘 n-1 次。     

**减常因子** 技术意味着在算法的每次迭代中，总是从实例的规模中减去一个相同的常数因子。在大多数
应用中，这样的常数因子等于2.    

@TODO    

继续看指数问题，规模减半的实例计算就是 a<sup>n/2</sup> 的值，它们之间有着明显的关系：
a<sup>n</sup> = (a<sup>n/2</sup>)<sup>2</sup>。但因为我们只考虑整数指数的问题实例，
前面这个办法只对偶数 n 有效。如果 n 是奇数，我们必须使用偶指数规则计算 a<sup>n-1</sup>,
然后把结果乘以 a。    

这样该算法的复杂度为 θ(logn)。    

感觉减治法就是把方案一致减下去，然后再简单地把结果合起来。分治法的话，好像在合并的时候要进行
很多复杂的操作。   



## 4.4 减常因子算法

### 4.4.1 折半查找

略。   

### 4.4.2 假币问题

在 n 枚外观相同的硬币中，有一枚是假币。在一架天平上，我们可以比较任意两组硬币。也就是说，
通过观察天平是右倾、左倾还是停在当中，我们可以判断出两组硬币重量是否相同。已知假币较轻。   

这里说这个问题的意思是，如果我们在比较的时候将硬币分 3 堆，效率要比 2 堆更好。   

### 4.4.3 约瑟夫问题

这里这样描述这个问题，1-n 共 n 个人，编号从 1 开始，假设一直消去编号为 2 的人。    

把奇数 n 和偶数 n 的情况分开来考虑会比较方便一些。如果 n 为偶数，也是说 n = 2k，对整个
圆圈处理第一遍之后，生成了同样问题的规模减半的实例。它们的唯一差别是位置的编号。例如，一个
初始位置为 3 的人在第 2 轮会处在 2 号位置上，依次类推。很容易发现，为了得到一个人的初始
位置，我们只需要将它的新位置乘 2 再减 1，也就是：   

J(2k) = 2J(k) - 1     

然后考虑 n 为奇数的情况，也就是 n = 2k+1。第一轮消去了所有偶数位。如果我们把紧接着消去的位置
1 上的人也加进来，我们留下一个规模为 k 的实例。这里，为了得到与新的位置编号相对应的初始位置
编号，我们必须把新的位置编号乘 2 再加 1，因此，对于奇数 n，有：   

J(2k + 1) = 2J(k) + 1     

## 4.5 减可变规模算法

### 4.5.1 计算中值和选择问题

选择问题是求一个 n 个数列表的第 k 个最小元素的问题。     

在不使用排序的情况下，可以使用 **划分**(partition) 的思路。有两种主要的划分算法，这里讨论
Lomuto 划分。这个划分好像就是单路快排的那种划分方法。另一种划分好像就是双路快排的思路。   

# 第 5 章 分治法

先略。    

# 第 6 章 变治法

本章讨论一组设计方法，它们都基于变换的思想。我们把这种通用技术称为 **变治法**，因为这些
方法都是分成两个阶段工作的。首先，在“变”的阶段，出于这样或者那样的原因，把问题的实例变
得更容易求解。然后，在第二阶段或者说“治”的阶段，对实例进行求解。   

根据我们对问题实例的变换方式，变治思想有 3 种主要的类型：   

+ 变换为同样问题的一个更简单或者更方便的实例 —— 我们称之为 **实例化简**
+ 变换为同样实例的不同表现 —— 我们称之为 **改变表现**
+ 变换为另一个问题的实例，这种问题的算法是已知的 —— 我们称之为 **问题化简**    

## 6.1 预排序

下面的 3 个例子说明了预排序的思想：   

1. **检验数组中元素的唯一性**   

使用蛮力法对数组中所有的元素进行比较，直到找到两个相等的元素，或者所有的元素对都已比较完毕。
它的最差效率为 O(n^2)。   

换一种做法，可以先排序，然后只检查连续元素。复杂度方面，排序至少要 O(nlogn)，后面的检查要 O(n)。
因此最后的效率大约是 O(nlogn)。    

2. **模式计算**     

在给定的数字列表中最经常出现的一个数值称为 **模式**。例如，对于 5,1,5,7,6,5,7 来说，
模式是 5（如果若干个不同的值都是最经常出现的，它们中的任何一个都可以看做模式）。   

这个问题其实用个 Map 的话，复杂度最差也就是个 O(n) + O(n) = O(n)。    

书上给的解法是，先排序，这样所有相等的数值都会邻接在一起。要求出模式，我们只需要求出在该有序
数组中邻接次数最多的等值元素即可。    

那复杂度就是 O(nlogn) + O(n) = O(nlogn)。     

3. **查找问题**   

略。     

# 第 7 章 时空权衡

这个思想是对问题的部分或全部输入做预处理，然后将获得的额外信息进行存储，以加速后面问题的求解。
我们把这个方法称为 **输入增强**，这些算法是以它为基础的：   

+ 计数排序
+ Boyer-Moore 字符串匹配算法和霍司普尔提出的简化版本    

其他采用空间换时间权衡思想的技术简单地使用额外空间来实现更快和更方便的数据存取。我们把这个方法
称为 **预构造**。这个名字强调了这种空间换时间权衡技术的两个方法：所讨论的问题在实际处理以前
就做过某些处理了，但是输入增强技术不同，这个技术只涉及存储结构：   

+ 散列
+ 以 B 树作索引

还有一种和空间换时间权衡思想相关调度算法设计技术：动态规划。这个策略的技术是把给定问题中
重复子问题的解记录在表中，然后求得所讨论问题的解。   

## 7.2 字符串匹配中的输入增强技术

### 7.2.1 Horspool 算法

作为一个例子，考虑在一个文本中查找模式 BARBER。从模式的最后一个 R 开始从右向左，我们比较模式
和文本中的相应字符对。如果模式中所有的字符都匹配成功，就找到了一个匹配的字符串，就可停止
查找了。如果还希望查找同样模式的另一个匹配，就继续查找。    

如果遇到了一对不匹配字符，我们需要把模式右移。很明显，如果不存在错过文本中一个匹配子串的风险，
我们希望移动的幅度尽可能地大。假设文本中，对齐模式最后一个字符的元素是字符 c，Horspool 算法
根据 c 的不同情况来确定移动的距离，无论 c 是否和模式的最后一个字符相匹配。    

注意上面的意思，c 是我们开始匹配的时候的文本中从右向左的第一个字符。    

一般来说，会存在下面 4 种情况。   

+ 情况 1：如果模式中不存在 c（注意是在模式中压根不存在这个字符），模式安全移动的幅度就是它的
全部长度，这也好理解，因为这个模式里面没一个元素和这个 c 匹配，那直接整体跳过就好
+ 情况 2：如果模式中存在 c，但它不是模式的最后一个字符（在我们的例子中，c 就是字母 B），移动
时应该把模式中最右边的 c 和文本中的 c 对齐。     

```
s0, ....    B       .... s(n-1)
           !=
 B A R B E  R
     B A R  B E R
```     

+ 情况 3：如果 c 正好是模式中的最后一个字符，但是在模式的其他 m-1 个字符中不包含 c，移动的
情况类似情况 1，移动的幅度等于模式的全部长度 m。     

```
s0 ...    M   E   R    ... s(n-1)
         !=   =   =   
  L E A  D    E   R
                    L  E  A  D  E  R
```    

这里也好理解，就这一个字符，除了末尾部分其他都没了，那只要一遇到不匹配就可以整体移动了。    

+ 情况4：最后，如果 c 正好是模式中最后一个字符，而且在模式的前 m-1 个字符中也包含 c，移动
的情况就类似于情况 2，移动时应该把模式中前 m-1 个字符中的 c 和文本中的 c 对齐     

```
s0 ...      A   R    ... s(n-1)
           !=   =
  R E O R D E   R
        R E O   E D E R
```    

我们可以预先算出每次移动的距离并把它们存在表中。这个表是以文本中所有可能遇到的字符为索引的，
对于一个自然语言的文本来说，这些字符串包括空格、标点符号和其他一些特殊字符。我们将移动的距离
填入表中的单元格，具体来说，对于每一个字符 c，我们可以用以下公式算出移动距离：    

t(c) = 模式的长度 m（如果 c 不包含在模式的前 m-1 个字符中）
     = 模式的前 m-1 个字符中最右边的 c 到模式中最后一个字符的距离（在其他情况下）    

例如，对于模式 BARBER，除了 E, B, R, A 的单元格分别为 1,2,3,4 之外，其他的单元格都
等于 6.     

这里有一个简单的算法用来计算移动表中的每个单元格的值。初始时把所有的单元格都置为模式的长度 m，
然后从左到右扫描模式，将下列步骤重复 m-1 遍：对于模式中的第 j 个字符（0 &lt;= j &lt;= m-2)，
将它在表中的单元格改写为 m - 1 - j，这是该字符到模式右端的距离。注意，因为该算法是从左到右扫描
模式，一个字符的最后一次改写一次是在该字符最右边一次出现的时候。    

```
ShiftTable(P[0..m-1])

for j <- 0 to size-1 do Table[i] <- m
for j <- 0 to m-2 do Table[P[j]] <- m-1-j
return Table
```    

有了这个表就好了，我们匹配的时候一遇到不匹配的字符，直接按当前文本的最后一个字符在表中的值，
进行偏移。     

```js
function Horspool(text, pattern) {
  const {map, ok} = buildTable(text, pattern);
  if (!ok) {
    return -1;
  }

  const tLen = text.length;
  const pLen = pattern.length;
  for (let i = pLen-1; i < tLen; ) {
    let j = pLen-1;
    for (; j >= 0; j--) {
      if (text[i-pLen+j+1] !== pattern[j]) {
        i = i + map.get(text[i]);
        break;
      }
    }
    if (j === -1) {
      return i+1-pLen;
    }
  }
  return -1;
}

function buildTable(text, pattern) {
  const map = new Map();
  const tLen = text.length;
  const pLen = pattern.length;

  for (let i = 0; i < tLen; i++) {
    map.set(text[i], pLen);
  }

  for (let i = 0; i < pLen-1; i++) {
    if (!map.has(pattern[i])) {
      // 可以提前终止掉
      return {
        map: null,
        ok : false
      };
    }
    map.set(pattern[i], pLen-1-i);
  }
  return {
    map,
    ok: true
  };
}
```    

Horspool 算法的最差效率属于 O(nm)，但对于随机文本来说，它的效率是属于 O(n)的。而且，
虽然效率类型相同，但平均来说，Horspool 算法显然要比蛮力算法块很多。    

### 7.2.2 Boyer-Moore 算法

如果模式最右边的字符和文本中的相应字符 c 所做的初次比较失败了，该算法和 Horspool 算法
所做的操作完全一致。我们前面曾经解释过如何事先计算好一张表，这时，它也会按照从这张表中取出
的字符个数将模式向右移动相应的距离。   

然而，在遇到一个不匹配的字符之前，如果已经有 k(0 &lt; k &lt; m)个字符成功匹配了，这两个
算法的操作是不同的。    

在这种情况下，Boyer-Moore 算法会参考两个数值来确定移动的距离。第一个数值是由文本中的一个
字符 c 确定的，它导致了模式中的相应字符和它不匹配。因此我们把它称为 **坏符号移动**(bad-symbol shift)。
导致这种移动的原因和导致 Horspool 算法移动的原因是一样的。如果 c 不在模式中，我们把模式
移动到正好跳过这个字符的位置。为方便起见，可以用公式 t(c) - k 来计算移动的距离，其中 t(c)
是 Horspool 算法用到的预先算好的表中的单元格，而 k 是成功匹配的字符个数。