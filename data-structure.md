# 数据结构

<!-- TOC -->

- [数据结构](#数据结构)
- [动态数组](#动态数组)
- [栈](#栈)
- [队列](#队列)
- [循环队列](#循环队列)
- [链表](#链表)
- [链表队列](#链表队列)
- [二叉树](#二叉树)
  - [插入和查询操作](#插入和查询操作)
  - [遍历](#遍历)
  - [删除问题](#删除问题)
  - [二分搜索树的复杂度分析](#二分搜索树的复杂度分析)
- [映射和集合](#映射和集合)
- [堆和优先队列](#堆和优先队列)
  - [堆](#堆)
- [线段树（区间树）Segment Tree](#线段树区间树segment-tree)
- [Trie](#trie)
- [并查集 Union Find](#并查集-union-find)
- [AVL 树](#avl-树)
- [红黑树](#红黑树)
  - [2-3 树](#2-3-树)
  - [红黑树与 2-3 树的等价性](#红黑树与-2-3-树的等价性)
  - [红黑树添加节点的分析](#红黑树添加节点的分析)
  - [补充内容](#补充内容)
    - [旋转](#旋转)
    - [在旋转后重置父节点的链接](#在旋转后重置父节点的链接)
    - [向 2- 节点插入新键](#向-2--节点插入新键)
    - [向一颗双键树（即一个 3- 节点）中插入新键](#向一颗双键树即一个-3--节点中插入新键)
    - [颜色反转](#颜色反转)
    - [根节点总是黑色](#根节点总是黑色)
    - [向树底部的 3- 节点插入新键](#向树底部的-3--节点插入新键)
  - [总结](#总结)
- [B 树](#b-树)
  - [B 树的插入](#b-树的插入)
    - [分拆](#分拆)
- [图论](#图论)
  - [课程笔记](#课程笔记)
  - [Dijkstra 算法](#dijkstra-算法)
  - [Bellman-Ford 算法](#bellman-ford-算法)
  - [无向图](#无向图)
    - [邻接表](#邻接表)
  - [SQRT 分解](#sqrt-分解)

<!-- /TOC -->

# 动态数组

+ 插入操作：O(n)
+ 移除操作：O(n)
+ 修改操作：如果已知待修改元素索引 O(1)，否则 O(n)
+ 查询操作，同修改    
+ addLast: O(1) 均摊复杂度
+ addFirst: O(n)
+ removeLast: O(1) 均摊复杂度
+ removeFirst: O(n)

假设 capacity = n, n+1 次 addLast，触发 resize，总共进行了 2n+1 次基本操作（n+1 次插入，
n 次的 resize 中的数据搬移），平均每次 addLast 操作，进行 2 次基本操作。   

因此，可以认为 addLast 和 removeLast 的均摊复杂度为 O(1)。   

复杂度震荡。   

# 栈

LIFO, Last In First Out。    

Stack&lt;E&gt;   

+ void push(E)  O(1) 均摊复杂度
+ E pop()    O(1)  均摊复杂度
+ E peek()   O(1)
+ int getSize()   O(1)
+ boolean isEmpty()  O(1)  

栈的底层有多种实现方式。上面的复杂度都是针对数组栈的底层实现。   

# 队列

FIFO, First In First Out。    

Queue&lt;E&gt;   

+ void enqueue(E)   O(1) 均摊复杂度
+ E dequeue()   O(n)
+ E getFront()  O(1)
+ int getSize()  O(1)
+ bool isEmpty() O(1)  

对于队列，我们只对队首的元素感兴趣。    

复杂度均为数组队列实现。   

与栈相同，队列的底层也有多种实现方式，所以我们把队列和栈都定义成了接口，而不是独立的结构。
我们只关注队列和栈应该实现哪些操作，而不关注其底层是数组还是链表实现的等等。   

# 循环队列

数组队列的问题是，每次出队的时间复杂度都是 O(n)。这是不可接受的。   

因此，我们可以换种想法，在队列中添加两个指针，front 和 tail，front 指向队首元素，
tail 指向队尾的下一个元素。那么这样我们在出队时，只是去移动 front 指针，而不是真的去
从数组首部移除元素，那么这个时间复杂度就又会下降到 O(1).    

![circular-queue](https://github.com/temple-deng/markdown-images/blob/master/other/circular-queue.png)    

这里我们在 tail 到达数组尾部的时候，重新指向队首部分已经出队的元素，同时假设 tail + 1 = front
时，队列为满。这样当 front=tail 的时候，就只有在队列为空的时候。    

说实话，这里取余的操作还是有点不理解。    

根据性能测试的结果，如果是单纯入队的操作，循环队列的性能并不比数组队列更好，甚至在测试时，
是一直要比数组队列差的，但是加入了出队操作后，循环队列的性能要明显优于数组队列。   

但是奇怪的是，在视频中的用例中，这种差距是上百倍的，但自己的电脑上也就个位数倍的差距。   

LoopQueue&lt;E&gt;   

+ void enqueue(E)   O(1)
+ E dequeue()   O(1)
+ E getFront()  O(1)
+ int getSize()  O(1)
+ bool isEmpty() O(1)  

# 链表

+ 数据存储在“节点”中
+ 优点：真正的动态，不需要处理固定容量的问题
+ 缺点：丧失了随机访问的能力    

在只保留头指针的情况下，很多链表的操作，都要针对在头结点和其他节点的操作进行分情况讨论，
究其原因是头结点前没有节点了，因此，我们可以手动添加一个虚拟节点，来简化我们的代码。   

+ 添加操作：
  - addFirst: O(1)
  - addLast: O(n)
  - insert: O(n)
+ 删除操作：
  - removeFirst: O(1)
  - removeLast: O(n)
  - remove: O(n)
+ 修改操作 set: O(n)
+ 查找操作：
  - get: O(n)
  - contains: O(n)

综合来看，链表的增删改查的操作的时间复杂度均为 O(n) 级别的，要比动态数组要查，但是需要
注意的是在表头进行的查找，删除和添加操作时间复杂度都是 O(1)，因此，链表适合于只对表头
进行操作的场景。    

在实际测试时，单就链表栈和数组栈来说，很难说链表栈一定比数组栈性能更好，因为数组栈我们只在达到
容量后，进行一次扩容操作，时间主要花费在多次的扩容操作上。但是链表呢，虽然无需扩容操作，但是
链表需要不断在内存中寻找可用的空间，存放新加入的 Node 节点，这一步也可能是很耗时的。   

# 链表队列

由于队列需要在一头增加元素，在另一头删除元素，因此单纯的使用我们之前的链表，性能并不是很好的。
这时候我们可以利用我们在循环队列中提到过的方法，添加一个 tail 指针（或者节点），来指向链表的
另一端。但由于在 tail 端删除元素仍要循环整个链表。因此我们可以颠倒一下队列的前后。    

使用 head 来充当队列的队首，由于在 head 处进行删除操作的复杂度是 O(1) 级别的，因此出队操作的
复杂度就是 O(1) 级别的。tail 指向另一端的最后一个节点（注意这里不是说像添加 dummyHead 一样，
添加一个 dummyTail 节点，这里 tail 就指向最后一个元素节点）。同时需要注意的是，由于我们不会
对链表中间的元素进行插入删除操作，所以就不需要使用 dummyHead 来统一我们函数的编写。    

因此，这里 head 指向第一个元素节点，充当队首，进行出队操作，tail 指向最后一个元素节点，充当
队尾，进行入队操作。    

# 二叉树

+ 二叉树具有唯一根节点
+ 二叉树每个节点最多有两个孩子
+ 没孩子的节点叫叶子节点
+ 二叉树具有天然递归结构
+ 满二叉树：除了叶子节点以外，其他节点都有两个孩子
+ 一个节点也是二叉树，甚至 null 也可以看成二叉树   

二分搜索树 Binary Search Tree    

+ 二分搜索树也是二叉树
+ 二分搜索树的每个节点的值：
  - 大于其左子树的所有节点的值
  - 小于其右子树的所有节点的值
+ 每一颗子树也是二分搜索树
+ 存储的元素必须有可比较性   

注意我们这里的定义，二分搜索树中不包含重复的元素，如果要包含重复的元素，需要修改上面的定义，
把小于或者大于改为小于等于或大于等于即可。    

## 插入和查询操作

利用递归结构，可以很方便的实现。    

## 遍历

1. **前序遍历**    

先访问节点，再访问节点的左右子树。   

```js
function traverse(node) {
  if (node == nill) {
    return;
  } else {
    // do sth
  }

  traverse(node.left);
  traverse(node.right);
}
```   

2. **中序遍历**    

先访问左子树，然后访问节点，再访问右子树。   

注意中序遍历的结果是一个排好序的结果。   

3. **后序遍历**    

先访问左右子树，再访问节点    


前中后三种遍历方式都是深度优先遍历的实例。    

而层序遍历是广度优先遍历的实例。    

## 删除问题

删除最小值：最小值一定是最左边的那个枝杈或者叶子节点，如果是叶子节点，那直接删除就好，但
如果是枝杈，那一定是有右子树，这种情况上直接把右子树整体提上来就好，即让右子树替换掉这个
枝杈。    

删除最大值：同理，最大值也类似。    

在删除任意值时，如果节点只有一边子树，这种情况是比较容易操作的，直接把子树上提即可。但是
如果有两边子树，那就比较复杂了，我们需要在左边子树中找到前驱，或者在右边子树中找到后继。
然后把这个节点先从原位置删除，然后再把这个节点替换掉要删除的节点，处理好子树的顺序即可。   

## 二分搜索树的复杂度分析

+ add, remove, contains 都是 O(h) 级别的，h是树的深度，O(h) = O(logn) logn 是一种
平均复杂度，最差的情况下 h = n，这是复杂度就是 O(n)

# 映射和集合

集合和映射的底层都可以使用链表或二分搜索树来实现，但需要注意的是使用二叉搜索树的实现，
要求键名必须是可排序的。   

# 堆和优先队列

优先队列的时间复杂度：   

+ 普通线性结构的底层实现：
  - 入队：O(1)
  - 出队：O(n)
+ 顺序线性结构的底层实现：
  - 入队：O(n)
  - 出队：O(1)
+ 堆
  - 入队：O(logn)
  - 出队：O(logn)

## 堆

二叉堆：   

+ 完全二叉树：不一定是满二叉树，但是其缺少的部分一定在树的右下方。    
+ 堆中某个节点的值总是不大于其父节点的值。这种情况的堆称为最大堆。相应的，我们可以定义最小堆。   

@TODO


如果索引从 0 开始，则 parent = (i-1)/2, leftChild = 2i + 1, rightChild = 2i + 2。    

我们可以使用动态数组来实现一个堆。   

+ **Sift Up**：添加元素的时候直接添加到数组的末尾，由于此次添加可能会打破堆的排列原则，
所以我们可能有必要将这个元素进行上浮，找到一个它适合的位置或者到堆顶，这个操作叫做 Sift Up
+ **Sift Down**：同理在删除最大的元素的时候，我们并不是进行左右两个子树的重组，而是首先
将数组尾部的那个元素提到堆顶，然后将其慢慢下沉，这个操作叫 Sift Down.怎么沉呢，具体就是
不断地找元素本身，元素的左右两个子节点中最大的那个，然后两个调换位置，直到满足最大堆的定义位置
或者到了叶子节点。   

复杂度方面:   

+ add 和 removeMax 的时间复杂度都是 O(logn)，而且由于堆是一个完全二叉树，所以其时间
复杂度是不会退化成 O(n) 级别的。   
+ replace 和 heapify
  - replace: 是指将最大元素取出，并插入一个新的元素值，一种简单的解法就是直接 removeMax
  然后再 add 一下，这样的话时间复杂度就是 O(2logn)，另一种思路是，我们直接用新添加的元素
  替换掉堆顶元素，然后执行 sift down，这样复杂度就是 O(logn)
  - heapify: 是指给一个乱序的数组，然后对其进行处理，使其满足一个最大堆，解法是从最后一个
  非叶子节点开始，知道堆顶节点，逐个进行 Sift Down 操作，复杂度是 O(n)


原地堆排序，每次把最后一个元素与第一个元素交换，然后处理前 n-1 个元素。   

# 线段树（区间树）Segment Tree


&nbsp; | 使用数组实现 | 使用线段树
---------|----------|---------
 染色操作（更新区间） | O(n) | O(logn)
 查询操作（查询区间） | O(n) | O(logn)    

@TODO    

+ 线段树是平衡二叉树
+ 如果区间有 n 个元素，数组表示需要有 4n 的空间

# Trie

查询每个条目的时间复杂度和字典中一共有多少条目无关。而跟字符串的长度有关，具体来说，字符串长度
为 l，则时间复杂度就是 O(l)。    

每个节点有 26 个指向下个节点的指针。考虑到不同的语言和不同情景，可能 26 个是多余或者不够的。   

因此通常我们经常让每个节点有若干个指向下个节点的指针。并且让这些指针保存到一个 map 里，将
map 保存在 trie 中。   

```java
class Node {
  char c;
  Map<char, *Node> next;
}
```  

```java
class Node {
  boolean isWord;
  Map<char, *Node> next;
}
```   

# 并查集 Union Find

并查集可以非常迅速地判断网络中节点间的连接状态。   

对于一组数据，主要支持两个动作：   

+ union(p, q)
+ isConnected(p, q)    

并查集也可以有不同的底部实现。   

并查集的基本数据表示：   

```
0  1  2  3  4  5  6  7  8  9 
-----------------------------
0  0  0  0  0  1  1  1  1  1
```   

上面的数字代表并查集中元素的一个编号。下面的数字代表元素所属的集合的 ID。例如上面
0~4 编号元素属于 ID 为 0 的集合，另外的元素属于一个集合。    

@TODO   

上图是 Quick Union 实现的一种简要表示

# AVL 树

+ 平衡二叉树：对于任意一个节点，左子树和右子树的高度差不能超过 1
+ 什么时候要进行维护平衡的操作呢，显然，我们是在插入一个节点后，可能会破坏了二叉树的平衡限制，
因此，我们的维护操作应该放到插入节点后。   

1. **LL**    

当在不平衡节点的左侧的左侧添加节点时，这种情况叫做 LL, 要进行一次右旋转：  

![](https://raw.githubusercontent.com/temple-deng/markdown-images/master/other/ll.png)   

2. **RR**    

当在不平衡节点的右侧的右侧添加节点时，这种情况叫做 RR，要进行一次左旋转:   

![rr1](https://raw.githubusercontent.com/temple-deng/markdown-images/master/other/rr1.png)   

![rr2](https://raw.githubusercontent.com/temple-deng/markdown-images/master/other/rr2.png)   

3. **LR**   

当在不平衡节点的左侧的右侧添加节点时，这种情况叫做 LR, 要先对左子树进行左旋转，再对不平衡
节点进行右旋转。   

4. **RL**    

当在不平衡节点的右侧的左侧添加节点时，这种情况叫做 RL，要先对右子树进行右旋转，再对不平衡
节点进行左旋转。    

# 红黑树

+ 红黑树依然是一颗二分搜索树
+ 每个节点或者是红色，或者是黑色的
+ 根节点是黑色的
+ 每一个叶子节点（最后的空节点）是黑色的，要注意这里对叶子节点的定义
+ 如果一个节点是红色的，那么他的孩子节点都是黑色的
+ 从任意一个节点到叶子节点，经过的黑色节点是一样的   

## 2-3 树

+ 2-3 树满足二分搜索树的基本性质
+ 但是 2-3 树不是一颗二叉树，因为 2-3 树有两种节点，一种节点可以存放一个元素，一种节点可以存放两个元素    
+ 每个节点或者有两个孩子，或者有三个孩子，有两个孩子的节点包含一个值，叫做 2 节点，有 3 个
孩子的包含两个值，叫做 3 节点
+ 上面所谓的满足二分搜索树的性质是指，在两个孩子的情况下，与二分搜索树一致，在三个孩子的情况，
如下所示，小于 b 的在左子树，大于 b 小于 c 的在中子树，大于 c 的在右子树。
+ 2-3 树是一颗绝对平衡树

```
      a               b  c
    /   \           /   |   \
```       

如何维护绝对平衡性：   

+ 首先，新节点绝对不会添加到空的位置   

例如首先我们有一颗以 42 为根的 2-3 树，并且这也是树中唯一的节点，现在要插入一个值为 37
的节点，按二分搜索树的定义，我们理论上应该添加到左子树中，但目前左子树是空，因此不能插入。
此时这个 37 应该融合到我们安装二分搜索树寻找添加位置过程中寻找到的最后一个叶子节点，因此
这里就是和 节点 42 融合。   

`37 | 42`    

假设现在又要添加一个 12 的节点，这时仍然先进行融合：   

`12 | 37 | 42`    

这时，2-3 进行分裂：   

```
    37
  /    \
 12    42
```   

假设这时又要添加一个值为 18 的节点，按照二分搜索树的规律，我们应该添加到 12 的右子树中，
这里值为 12 的节点就是我们最后找到的叶子节点，此时 18 应与 12 融合：   

```
     37
   /    \
12 | 18  42
```    

然后再添加一个 6，也是与值为 12 的节点进行融合，这时又要进行分裂，但这里分裂就不像上面
那么简单了，因为按照上面那样拆解，就不是一颗绝对平衡树了。    

如果一个叶子节点已经是一个 3 节点了，添加一个节点变成了 4 节点，这时必须进行分裂，我们
首先还是将 4 节点拆分成一个 3 个 2 节点的子树，之后，新的根节点，在这里就是值为 12
的节点，向上与父节点进行融合，这里父节点 37 是一个 2 节点，所以是可以直接融合的。融合
后，12 的左子树变成了融合节点左子树，12 的右子树变成了融合节点的中子树：    

```
        37                        37                               12 | 37
     /      \     分裂          /     \      12 向上融合            /   |    \
6 | 12 | 18  42   ===>        12      42    ===========>         6    18    42
                            /    \
                           6     18
```    

然后再添加一个 11 的节点，变成这样：    

```
        12 | 37
    /      |     \
  6 | 11   18     42
```    

这时又要添加一个值为 5 的节点，这里我们按照上面的方法，进行 3 节点融合为 4 节点，4 节点
分裂，根节点向上融合，但这里根节点 6 的父节点已经是一个 3 节点，融合后又成了一个 4 节点，
所以还要进行分裂。      

```
        12 | 37                         6 | 12 | 37 
      /    |    \     6向上融合         /   |    |    \     再次分裂
     6     18   42    ========>       5   11   18    42    ======>
   /  \
  5   11


                12
              /    \
             6     37
           /  \    /  \
          5   11  18   42
```     

## 红黑树与 2-3 树的等价性

红黑二叉树背后的思想是用标准的二叉查找树（完全由 2- 节点构成）和一些额外的信息（替换 3- 节点）
来表示 2-3 树。我们将树中的链接分为两种类型：红链接将两个 2- 节点连接起来构成一个 3- 节点，
黑链接则是 2-3 树中的普通链接。确切地说，我们将 3- 节点表示为由一条左斜的红色链接相连的
两个 2- 节点。   

方便起见，因为每个节点都只会有指向自己的链接（从它的父节点指向它），我们将链接的颜色保存
在表示节点 Node 数据类型的布尔变量 color 中。我们约定空节点为黑色。当我们提到一个节点的
颜色时，我们指的是指向该节点的链接的颜色。    

![rbtree and 2-3tree](https://raw.githubusercontent.com/temple-deng/markdown-images/master/other/rbtree_2-3tree.png)

+ 所有的红色节点都是左倾斜的。    
+ 没有任何一个结点同时和两条红链接相连。首先这里的两条红链接应该是既和父亲是红链接，又和左孩子
是红链接。因为红链接代表了 2-3 树的一个 3- 节点，那两个相连的红链接代表了一个 4- 节点，而 4-
节点是要分裂的，因为不存在两条相连的红链接。
+ 该树是完美黑平衡的，即任意空链接到根节点的路径上的黑链接数量相同。   


## 红黑树添加节点的分析

首先，我们要确认一点的就是，由于我们的红黑树是与 2-3 树等价的，因此，我们每次的添加节点，
事实上都是往一个节点中先进行融合操作，因此，我们将新建的节点的默认颜色设置为红色，因为
红色表示节点是和父节点在 2-3 树中是一个融合的节点。    

我们首先分析一下往一个 2 节点中融合一个节点的情况，新节点肯定要么比 2 节点数值大，要么
比 2 节点数值小。当比 2 节点小时，节点融合到左边，生成一个左孩子，这种情况下，这样就结束了。    

当比 2 节点数值大时，节点融合到右边，生成一个右孩子，此时右孩子是一个红节点，不满足红黑树
的定义，需要进行一次左旋转。旋转后，原 2 节点颜色变为红色，因为融合了嘛。新节点是原 2 节点
的颜色。    

当往一个 3 节点中融合一个节点的情况时，则新节点可能融合到 3 节点的左中右 3 个位置。    

首先分析融合到右边，这时形成一个 4 节点，此时按照 2-3 树的规则，要进行分裂，分裂成 3 个
2 节点，分裂后 3 个节点都是黑节点，但是此时还没结束，如果原 3 节点不是树的根的话，我们分裂
后的 3 个 2 节点中的充当父节点的那个节点要向上与其父节点进行融合，那这种情况下又要分情况
讨论，如果其父节点是 2 节点，则形成的父 2 节点是红色，否则其父节点是 3 节点，又要分裂，
则分裂后该节点还是黑色。    

这种情况下，在融合时，两边都是红节点，融合分裂后，两边都成了黑节点，而父节点再向上继续融合
前，暂时变为了红色，表示其要与父节点融合。这样三个节点的颜色都反转了，这一现象就叫做颜色反转。    

![insert](https://raw.githubusercontent.com/temple-deng/markdown-images/master/other/red_black.png)


## 补充内容

这一部分是摘自书上的针对红黑树的操作介绍。    

### 旋转

在我们实现的某些操作中可能会出现红色右链接或者两条连续的红链接，但在操作完成前这些情况都会被
小心地旋转并修复。旋转操作会改变红链接的指向。首先，假设我们有一条红色的右链接需要被转化为
左链接。这个操作叫 **左旋转**，它对应的方法接受一条指向红黑树中的某个节点的链接作为参数。    

假设被指向的结点的右链接是红色的，这个方法会对树进行必要的调整并返回一个指向包含同一组键的子树
且其左链接为红色的根节点的链接。这个操作很容易：我们只是将两个键中的较小者作为根节点变为将
较大者作为根节点。实现一个红色左链接转换为一个红色右链接一个 **右旋转** 的代码完全相同，只
需要将 left 换成 right 即可。     

@TODO    

这个应该是一般在一个 2- 节点的右侧组合成一个 3- 节点吧。不过应该是也可能在一个 3- 节点的
中间组合了。这种还没想到。    

```go
func (this *RBTree) rotateLeft(h *Node) *Node {
  x := h.right
  h.right = x.left
  x.left = h
  x.color = h.color
  h.color = RED
  return x
}
```   

右旋：    

```go
func (this *RBTree) rotateRight(h *Node) *Node {
  x := h.left
  h.left = x.right
  x.right = h
  x.color = h.color
  h.color = RED
}
```    

这里给定例子都太少了，很难想象出具体的样子。   


### 在旋转后重置父节点的链接

无论是左旋转还是右旋转，旋转操作都会返回一条链接。我们总是会用 rotateRight() 或 rotateLeft()
的返回值重置父节点中相应的链接。返回的链接可能是左链接也可能是右链接，但是我们总会将它赋予父节点
中的链接。这个链接可能是红色也可能是黑色—— rotateLeft() 和 rotateRight() 都通过将
x.color 设为 h.color 保留它原来的颜色。这可能会产生两条连续的红链接，但我们的算法会继续用
旋转修正这种情况。例如，代码 h = rotateLeft(h)；将旋转节点 h 的红色右链接，使得 h 指向了
旋转后的子树的根节点。    

在插入新的键时，我们可以用旋转操作帮助我们保证 2-3 树和红黑树之间的一一对应关系，因为旋转操作
可以保持红黑树的两个重要性质：有序性和完美平衡性。有序性可以理解，因为我们是按照二叉树的方式
找位置，肯定是有序的，完美平衡性有点不好理解，参考 AVL 树中的旋转操作，就是用来保证有序性和
完美平衡性的。下面我们来看看如何使用旋转操作来保持红黑树的另外两个重要性质（不存在两条连续
的红链接和不存在红色的右链接）。     

### 向 2- 节点插入新键

首先确定一点，就是完美新建的节点是红色的。那么和一个 2- 节点插入，就是两种情况，左或者右，如果
是左插，没有任何问题，新节点和父节点形成一个 3- 节点。如果是右插，那么就出现了右红链的问题，
需要进行一个左旋转。     

### 向一颗双键树（即一个 3- 节点）中插入新键

这种情况又可分为三种子情况：新键小于树中两个键，在两者之间，或是大于树中两个键。每种情况
中都会产生一个同时连接到两条红链接的节点，而我们的目标就是修正这一点。（这里把一个节点左右双红
也算到双红链接里面）    

+ 新键大于原树两个键时，链接到 3- 节点的右链接。这时候我们需要将两条链接的颜色都由红变黑。
+ 新键小于原树中的两个键，链接到最左边的空链接，这时产生两条连续的红链。此时需要将上层的红链
右旋转即可得到第一种情况。
+ 如果新键介于原树中的两个键之间，这又会产生两条连续红链。此时需要将下层的红链接左旋转即可得到
第二种情况。    

### 颜色反转

我们专门用一个方法 flipColors() 来转换一个节点的两个红色子节点的颜色。除了将子节点的颜色由
红变黑之外，我们同时还要将父节点的颜色由黑变红。    

这里其实颜色反转，对应着 4- 节点的裂变，而父节点由黑变红是指 4- 节点裂变后，父节点要向上融合，
因此改为红色。   

这里可能会问为什么父节点一定是黑色呢，因为这原本是一个 3- 节点啊，3- 节点的根肯定是黑色的啊。    

### 根节点总是黑色

上节的颜色反转可能会使根节点变为红色。我们需要在每次插入后将根节点设为黑色。    

### 向树底部的 3- 节点插入新键

同向一颗双键树（即一个 3- 节点）中插入新键。    

## 总结

好了这里我们好好总结一下。    

首先，左旋转，右旋转，颜色反转和保证根节点为黑。这 4 种操作都是为了保证在插入节点后，整个红黑
树还能保持性质时可能会执行的额外的操作。     

然后，我们具体分析一下插入的几种情况。    

首先，我们可以根据往一个 2- 节点插和往一个 3- 节点插，将插入分成两大类。   

**2- 节点插入**    

2- 节点插入比较简单，首先其实我们可以确定 2- 节点的原节点肯定是黑色的。然后分情况讨论。当往
左边插入时，生成一个 3- 节点，流程到此为止即可。   

当往右边插入时，生成一个右红链接的 3- 节点，右红链接怎么办？左旋转。    

**3- 节点插入**    

分左中右3个方向的插入。    

往右插时，出现左右双红链接，进行颜色反转，中节点变红。   

往左插时，出现两条连着的红链接。这时候把 3- 节点的中节点（也就是中间那层）进行右旋转，旋转为
出现了上一种情况，左右双红，颜色反转，中节点变红。   

往中间插时，出现上左下右两条相连红链接。这时候把下层的红链接进行左旋，注意是下层进行左旋，不是整体
左旋，然后就出现了上一种情况。    

# B 树

B 树：   

+ 或者为空；
+ 或者包含 n 个键值和 n+1 颗子树，每颗子树也是一颗 B 树。这些键值和子树分别即为 k1, k2,
..., kn 和 c1, c2, ..., cn+1。    

例如一颗 B 树的节点可能是这样的：   

```
      k1   k2  ...    kn
    /    |     |    |   \ 
   c1   c2    .... cn   cn+1
```    

节点中所有键值和子树都满足下面的限制条件：   

+ 所有键值按照单调递增顺序保存。即 k1 &lt;= k2 &lt;=...., &lt;= kn;
+ 对于任意 ki, 子树 ci 中的所有元素都不大于 ki, 且 ki 不大于子树 ci+1 的任意元素。   

最后为了保证平衡性，B 树还满足一些额外的要求：   

+ 所有的叶子节点具有相同的深度（意味着一颗满叉树？）；
+ 定义整数 t，称为 B 树的最小度数：
  - 每个节点最多含有 2t-1 个键值（那也就是最多含有 2t 个孩子）
  - 除根节点外，每个节点最少含有 t-1 个键值    

考虑一颗含有 n 个键值的 B 树，最小度数 t >= 2，树的高度为 h。出根节点外的全部节点至少含有
t-1 个键值。因为根节点至少含有一个键值，所以至少有两个深度为 1 的子节点（根的深度为0），
至少有 2t 个深度为 2 的子节点，至少有 2t<sup>2</sup> 个深度为 3 的子节点。。。。最后，
至少有 2t<sup>h-1</sup> 个深度为 h 的叶子节点。除根节点外，将节点个数乘以 t-1，就可以
得到 B 树中存储的全部元素个数，它必然满足下面的不等式：   

```
n >= 1 +(t-1)(2 + 2t + 2t^2 + ... + 2t^(h-1))
   = 2t^h - 1
```    

于是可以导出 B 树的高度和元素数满足下面的关系：    

h &lt;= log<sub>t</sub>((n+1) / 2)    

最简单的B树称为2-3-4树。它的最小度数 t = 2 ,除根节点外的任何节点都包含2到4个键值。

## B 树的插入

和 2-3 树插入一样，如果插入的叶子节点度数不够 2t-1，则可以直接融合，否则就需要额外的处理。
有两种方法能够解决它。   

### 分拆

我们可以通过对节点进行分拆解决插入时的平衡问题。有两种分拆方法：一种是插入前预先将可能超限
的节点进行分拆，另一种是先插入后再通过分拆节点修复平衡。   

这里只介绍一下先插入后再修复平衡的方案。   

# 图论

## 课程笔记

邻接矩阵与邻接表：   

+ 邻接矩阵就是用二维矩阵来表示点和点之间的连接关系，矩阵的元素值可以是布尔值，在无权图中 i 行
j 列的值为 true，则表示图中存在一条 i -&gt; j 的边，也可以是具体数值，用来在有权图中表示
两个顶点之间的边的权重，介于矩阵可能要开辟大量的内存空间，因此通常适合于表示稠密图
+ 邻接表其实也是一个二维数组，只是其中每一维的数组的长度不再是一个长为 n（n 为图中顶点数）
的数组，而是一个与其相邻的顶点的数组，当然也可以是一个链表结构。邻接表适合于表示稀疏图。   

最小生成树 Minimum Span Tree 针对带权无向图，通常也是针对连通图。    

**切分定理**(Cut Property)

+ 切分：把图中的节点分成两部分，成为一个 **切分** Cut
+ 横切边：如果一个边的两个端点，属于切分不同的两边，这个边称为 **横切边**(Crossing Edge)
+ 切分定理：给定任意切分，横切边中权值最小的边必然属于最小生成树    

有了切分定理，我们简单叙述一下思路，首先选择一个起点，然后做切分，将起点的所有横切边推入
一个最小堆中，然后找出堆顶的那条边。有了那条边，我们就有了第二个顶点，然后再做切分，把新
出现的横切边再推入之前的堆中，然后再将堆顶元素弹出，这样一直下去，知道最后连接所有顶点，
但是这样做会出现一个问题，就是可能在我们不停地进行切分的同时，堆中有一些横切边其实现在已经
不属于横切边了，这样当我们后续弹出堆顶元素的时候，如果遇到了重复的节点，其实就暗示了这
不是一条横切边了，这样其实直接出堆就好，但不需继续，我们还要继续出堆。    

上面就是 lazy prim 算法的简单思路，之所以叫 lazy 是因为在不断切分的过程中，我们并没有主动
去堆中把非横切边的边取出，而是直到出栈时遇到横切边才进行处理。   

LazyPrim 的时间复杂度是 O(ElogE) 级别的，而正常的 Prim 算法是 O(ElogV)。    

Kruskal 是 O(ElogE)。    

## Dijkstra 算法

Dijkstra 单源最短路径算法的前提是：图中不能有负权的边。复杂度 O(ElogV)。   

![dj1](https://raw.githubusercontent.com/temple-deng/markdown-images/master/dsa/dj1.png)    

首先确定起始点，建立路径表。    

![dj2](https://raw.githubusercontent.com/temple-deng/markdown-images/master/dsa/dj2.png)    

由起点 0 可以访问到节点 1, 2, 3。更新路径表。    

![dj3](https://raw.githubusercontent.com/temple-deng/markdown-images/master/dsa/dj3.png)    

这时在所有未访问的的节点中，到达节点 2 的路径是最短的，因此这条路径一定是我们达到节点 2 的最短
路径，因为我们目前所有已访问的路径中到达 2 的路径就已经比这条路径长了，如果再绕一下其他的
节点，那路径只会更长不会更短，因此这条路径就是达到节点 2 的最短路径。   

![dj4](https://raw.githubusercontent.com/temple-deng/markdown-images/master/dsa/dj4.png)    

确定了一个到达节点 2 的最短路径后，我们就可以将节点 2 标为已访问的。然后进行松弛操作，即由
节点 2 开始，探查其所有邻边。更新路径表。    

![dj5](https://raw.githubusercontent.com/temple-deng/markdown-images/master/dsa/dj5.png)    

然后发现，到节点 1 的路径 3 是目前到未访问的节点的路径中最短的那条。则开始访问节点 1。访问
节点 1 所有的邻边。   

![dj6](https://raw.githubusercontent.com/temple-deng/markdown-images/master/dsa/dj6.png)    

进行松弛操作。    

![dj7](https://raw.githubusercontent.com/temple-deng/markdown-images/master/dsa/dj7.png)    

然后发现到节点 4 的路径 4 是目前到未访问的节点的路径中最短的那条。则开始访问节点 4.    

![dj8](https://raw.githubusercontent.com/temple-deng/markdown-images/master/dsa/dj8.png)    

后续再访问节点即可。   

## Bellman-Ford 算法

前提：图中不能有负权环。  

复杂度 O(EV)。    

如果一个图没有负权环，从一点到另外一点的最短路径，最多经过所有的 V 个顶点，有 V-1 条边。
否则，存在顶点经过了两次，即存在负权环。   



## 无向图

就定义而言，顶点叫什么名字并不重要，但我们需要一个方法来指代这些顶点。一般使用 0 至 V-1
来表示一张含有 V 个顶点的图中的各个顶点。这样约定是为了方便使用数组的索引来编写能够高效
访问各个顶点中信息的代码。用一张符号表来为顶点的名字和 0 到 V-1 整数值建立一一对应的关系
并不困难。   

当两个顶点通过一条边相连时，我们称这两个顶点是相邻的，并称该连接依附于这两个顶点。某个顶点的
度数即为依附于它的边的总数。。    

在图中，路径是由边顺序连接的一系列顶点。简单路径是一条没有重复顶点的路径。环是一条至少含有一条
边，且起点和终点相同的路径。简单环是一条（除了起点和终点必须相同之外）不含有重复顶点和边的环。    

当两个顶点之间存在一条连接双方的路径时，我们称一个顶点和另一个顶点是连通的。    

如果从任意一个顶点都存在一条路径到达另一个任意顶点，我们成这幅图是 **连通图**。一幅非连通的
图由若干连通的部分组成，它们都是其极大连通子图。   

树是一幅无环连通图。连通图的 **生成树** 是它的一幅子图，它含有图中的所有顶点且是一棵树。   

当且仅当一幅含有 V 个节点的图 G 满足下列 5 个条件之一时，他就是一棵树：   

+ G 有 V-1 条边且不含有环
+ G 有 V-1 条边且是连通的
+ G 是连通的，但删除任意一条边都会产生一条环
+ G 是无环图，但添加任意一条边都会产生一条环
+ G 中的任意一对顶点之间仅存在一条简单路径    

无向图的 API：    

+ Graph(int V): 创建一个含有 V 个顶点但不含有边的图
+ Graph(In in): 从标准输入流 in 读入一幅图
+ int V(): 顶点数
+ int E(): 边数
+ void addEdge(int v, int w): 向图中添加一条边 v-w
+ Iterable&lt;Integer&gt; adj(int v): 和 v 相邻的所有顶点      

第二个构造函数接受的输入由 2E + 2 个整数组成：首先是 V 的数量，然后是 E 的数量，再然后是
E 对 0 到 V-1 之间的整数，每个整数对表示一条边。   

```
13
13
0   5
4   3
0   1
9   12
6   4
5   4
0   2
11  12
9   10
0   6
7   8
9   11
5   3
```    

### 邻接表

它将每个顶点的所有相邻节点都保存在该顶点对应的元素所指向的一张链表中。

## SQRT 分解    

- 数据结构
- 使用分块（分组）的思想
- 解决区间问题
